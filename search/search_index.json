{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"expert.ai essex Essex is a Web service that exposes the capabilities of one or more text intelligence engines through a RESTful API . Every text intelligence engine is produced with expert.ai Studio and, by default, it provides comprehensive document analysis capabilities based upon expert.ai NLU technology for a given language. If properly programmed, it also provides custom document classification and/or information extraction capabilities. Essex is designed to be easily integrated so to add the aforementioned capabilities to any application. Requirements Installation Setup and run API guide API reference","title":"Introduction"},{"location":"#expertai-essex","text":"Essex is a Web service that exposes the capabilities of one or more text intelligence engines through a RESTful API . Every text intelligence engine is produced with expert.ai Studio and, by default, it provides comprehensive document analysis capabilities based upon expert.ai NLU technology for a given language. If properly programmed, it also provides custom document classification and/or information extraction capabilities. Essex is designed to be easily integrated so to add the aforementioned capabilities to any application. Requirements Installation Setup and run API guide API reference","title":"expert.ai essex"},{"location":"guide/","text":"API Guide Capabilities Essex API capabilities are divided into three groups: Document analysis , comprising: Deep linguistic analysis , which, in turn, comprises: Text subdivision Part-of-speech tagging Morphological analysis Lemmatization Syntactic analysis Semantic analysis Keyphrase extraction Named Entity Recognition Relation extraction Sentiment analysis Document classification Information extraction Document analysis is a standard feature which is available by default in every text intelligence engine produced with expert.ai Studio . Document classification and information extraction, instead, are custom features corresponding to the work of Knowledge Engineers that have instructed the engine to determine what documents are about and to recognize & extract specific text from documents. The following articles in this section are devoted to describe all the capabilities. REST interface The API has a REST interface that accepts and returns JSON objects. Whenever a client program has to analyze a text, it requests an API resource sending the text to analyze, together with parameters, as a JSON payload that's an integral part of the request. This is similar to what happens when you you submit a form from a page of Web site using a browser: the submit button sends a request along with a payload constituted by form data. The request contains the path the resource has inside the API, that is its URL, or endpoint . The POST method is used because it allows to send data, i.e. the JSON object, to the API. Presented with this request, essex responds synchronously (after an amount of time depending on the type of processing requested, the complexity and the length of the text) by returning the requested resource, that is another JSON object. In the reference section of this manual you will find all the information about the endpoints , the JSON objects to send with requests and the JSON objects returned by essex.","title":"Overview"},{"location":"guide/#api-guide","text":"","title":"API Guide"},{"location":"guide/#capabilities","text":"Essex API capabilities are divided into three groups: Document analysis , comprising: Deep linguistic analysis , which, in turn, comprises: Text subdivision Part-of-speech tagging Morphological analysis Lemmatization Syntactic analysis Semantic analysis Keyphrase extraction Named Entity Recognition Relation extraction Sentiment analysis Document classification Information extraction Document analysis is a standard feature which is available by default in every text intelligence engine produced with expert.ai Studio . Document classification and information extraction, instead, are custom features corresponding to the work of Knowledge Engineers that have instructed the engine to determine what documents are about and to recognize & extract specific text from documents. The following articles in this section are devoted to describe all the capabilities.","title":"Capabilities"},{"location":"guide/#rest-interface","text":"The API has a REST interface that accepts and returns JSON objects. Whenever a client program has to analyze a text, it requests an API resource sending the text to analyze, together with parameters, as a JSON payload that's an integral part of the request. This is similar to what happens when you you submit a form from a page of Web site using a browser: the submit button sends a request along with a payload constituted by form data. The request contains the path the resource has inside the API, that is its URL, or endpoint . The POST method is used because it allows to send data, i.e. the JSON object, to the API. Presented with this request, essex responds synchronously (after an amount of time depending on the type of processing requested, the complexity and the length of the text) by returning the requested resource, that is another JSON object. In the reference section of this manual you will find all the information about the endpoints , the JSON objects to send with requests and the JSON objects returned by essex.","title":"REST interface"},{"location":"guide/categories-tree/","text":"Categories' tree The essex API exposes a self-documentation resource that is the tree of categories detected by document classification . Note This resource is useful\u2014and meaningful\u2014only if the text intelligence engine has been programmed to perform document classification. It must be requested using the POST method. In the reference section of this manual you will find: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Categories' tree"},{"location":"guide/categories-tree/#categories-tree","text":"The essex API exposes a self-documentation resource that is the tree of categories detected by document classification . Note This resource is useful\u2014and meaningful\u2014only if the text intelligence engine has been programmed to perform document classification. It must be requested using the POST method. In the reference section of this manual you will find: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Categories' tree"},{"location":"guide/classification/","text":"Document classification Document classification determines what the document text is about by mapping it to the categories of a tree . Unlike document analysis, which is available by default in any text intelligence engine deployed from expert.ai Studio , document classification is a custom feature corresponding to the work of Knowledge Engineers that have programmed the text intelligence engine using Studio IDE. In the reference section of this manual you will find all the information you need to perform document classification, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Overview"},{"location":"guide/classification/#document-classification","text":"Document classification determines what the document text is about by mapping it to the categories of a tree . Unlike document analysis, which is available by default in any text intelligence engine deployed from expert.ai Studio , document classification is a custom feature corresponding to the work of Knowledge Engineers that have programmed the text intelligence engine using Studio IDE. In the reference section of this manual you will find all the information you need to perform document classification, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Document classification"},{"location":"guide/entity-recognition/","text":"Named entity recognition Named entity recognition is a type of document analysis. It determines which entities\u2014persons, places, organizations, dates, addresses, etc.\u2014are mentioned in a text and the attributes of the entity that can be inferred by semantic analysis. Named entity recognition also performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned for entities corresponding to syncons of the expert.ai Knowledge Graph. In the case of actual places, geographic coordinates are also provided. Entities are also recognized in pronouns and shorter forms that refer to named mentions. This kind of by reference recognition is anaphoric because entities are recognized through anaphoras . For example in this text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan 's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. three mentions of Michael Jordan are recognized: the full named mention: Michael Jordan the anaphoras\u2014 Jordan and he \u2014for which Michael Jordan is considered the antecedent. In the reference section of this manual you will find all the information you need to perform named entity recognition, specifically: The types of named entities that essex is able to recognize. The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Named entity recognition"},{"location":"guide/entity-recognition/#named-entity-recognition","text":"Named entity recognition is a type of document analysis. It determines which entities\u2014persons, places, organizations, dates, addresses, etc.\u2014are mentioned in a text and the attributes of the entity that can be inferred by semantic analysis. Named entity recognition also performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned for entities corresponding to syncons of the expert.ai Knowledge Graph. In the case of actual places, geographic coordinates are also provided. Entities are also recognized in pronouns and shorter forms that refer to named mentions. This kind of by reference recognition is anaphoric because entities are recognized through anaphoras . For example in this text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan 's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. three mentions of Michael Jordan are recognized: the full named mention: Michael Jordan the anaphoras\u2014 Jordan and he \u2014for which Michael Jordan is considered the antecedent. In the reference section of this manual you will find all the information you need to perform named entity recognition, specifically: The types of named entities that essex is able to recognize. The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Named entity recognition"},{"location":"guide/extraction/","text":"Information extraction Information extraction detects meaningful parts of the document by mapping them to templates . It returns records \u2014you can think of a record as an instance of a template\u2014based on the text matched by extraction rules. Unlike document analysis, which is available by default in any text intelligence engine deployed from expert.ai Studio , information extraction is a custom feature corresponding to the work of Knowledge Engineers that have programmed the text intelligence engine using Studio IDE. In the reference section of this manual you will find all the information you need to perform information extraction, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Overview"},{"location":"guide/extraction/#information-extraction","text":"Information extraction detects meaningful parts of the document by mapping them to templates . It returns records \u2014you can think of a record as an instance of a template\u2014based on the text matched by extraction rules. Unlike document analysis, which is available by default in any text intelligence engine deployed from expert.ai Studio , information extraction is a custom feature corresponding to the work of Knowledge Engineers that have programmed the text intelligence engine using Studio IDE. In the reference section of this manual you will find all the information you need to perform information extraction, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Information extraction"},{"location":"guide/full-analysis/","text":"Full analysis Full document analysis is the sum of: Deep linguistic analysis Keyphrase extraction Named entity recognition . Relation extraction Sentiment analysis Document analysis is a standard feature which is available by default in every text intelligence engine produced with expert.ai Studio (no coding required). In the reference section of this manual you will find all the information you need to perform full document analysis, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Full analysis"},{"location":"guide/full-analysis/#full-analysis","text":"Full document analysis is the sum of: Deep linguistic analysis Keyphrase extraction Named entity recognition . Relation extraction Sentiment analysis Document analysis is a standard feature which is available by default in every text intelligence engine produced with expert.ai Studio (no coding required). In the reference section of this manual you will find all the information you need to perform full document analysis, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Full analysis"},{"location":"guide/keyphrase-extraction/","text":"Keyphrase extraction Keyphrase extraction is a type of document analysis that determines the key elements of a text: Relevant topics Main sentences Main phrases Main concepts Main lemmas Main concepts are returned as Knowledge Graph \"syncons\" and enriched through knowledge linking: open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned. In the case of actual places, geographic coordinates are also provided. Relevant topics are chosen from the Knowledge Graph. You can find a list of relevant topics in the reference section . In the reference section of this manual you will find all the information you need to perform keyphrase extraction, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Keyphrase extraction"},{"location":"guide/keyphrase-extraction/#keyphrase-extraction","text":"Keyphrase extraction is a type of document analysis that determines the key elements of a text: Relevant topics Main sentences Main phrases Main concepts Main lemmas Main concepts are returned as Knowledge Graph \"syncons\" and enriched through knowledge linking: open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned. In the case of actual places, geographic coordinates are also provided. Relevant topics are chosen from the Knowledge Graph. You can find a list of relevant topics in the reference section . In the reference section of this manual you will find all the information you need to perform keyphrase extraction, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Keyphrase extraction"},{"location":"guide/knowledgegraph/","text":"The Knowledge Graph The expert.ai Knowledge Graph is a concept-based representation of universal or domain-specific knowledge for a given language. Each entry in the Knowledge Graph corresponds to a concept. There are entries for common nouns, proper nouns, verbs, adjectives and adverbs. Each entry contains information, for example: The terms that can be used to express the concept in a text, for example hand, pass, pass on, hand off, turn over, reach . the corresponding part-of-speech\u2014for example (to) climb \u2192 verb\u2014and other grammatical information on the terms. The topics to which the concept corresponds, for example soprano \u2192 opera, singing. References to external knowledge bases such as Wikidata, DBpedia, GeoNames, etc. Extended proprieties, for example the coordinates of places. Modeling concepts that can be expressed in a language are not sufficient to enable the text analysis software to interpret ambiguous terms alone. For example, consider that in the expert.ai universal Knowledge Graph for the English language there are more than 20 entries for the verb (to) put . The single entry has statistical information indicating the frequency with which the concept is used in a reference corpus compared to other concepts that can be expressed with the same word. This information is useful for disambiguation, but insufficient. Using statistics alone can lead to incorrect interpretations and to a textual analysis of low quality and even lower usefulness. What really improves the results are the relationships between concepts, hence the term Knowledge Graph . A single entry is linked to one or more other entries and, as such, relationships can be numerous. For example, a concept can be connected to other concepts in the hierarchical relationship called \"IS-A\". So: sodium IS A alkaline metal IS A metal IS A element Or there can be a \"part-whole\" relationship: wheel IS A PART OF car clutch IS A PART OF car dashboard IS A PART OF car Relationships are designed to be navigated in both directions, so from the concept of car it is possible to discover the parts that make it up (wheels, clutch, dashboard, etc.) by navigating the \"IS PART OF\" relationships downstream. In the same way, for the \"IS-A\" relationship, starting from the concept of alkaline metal it is possible to discover which elements are \"types of\" the parent concept (sodium, cesium, lithium, etc.). Relationships can be one-to-many. If this is obvious for the \"part-whole\" relations if read from the \"whole\" to the parts and for the \"IS A\" relationship if read from the more generic concept to the more specific ones, it is not obvious in the opposite direction. However it can be, for example: cat IS A feline but also: cat IS A pet So it is possible that in a hierarchical relationship a concept can have multiple \"parents\". The relationships between Knowledge Graph entries are the foundations of solid disambiguation. Suppose the text contains a form of the verb (to) put . As stated, the standard English Knowledge Graph contains more than 20 different concepts that can be expressed with (to) put , but which is the right one? Relationships can help. The text analysis software can explore the relationships of each concept to find out if the concept itself is linked to other concepts expressed in the same text. The concept with more links to other concepts is a good candidate for the \"right concept\". The disambiguation of one word helps to disambiguate the others, but the text analysis software is always free to \"go back\" and correct its previous clarification choices as it proceeds with the analysis of the other words of the text, with a chain effect on other disambiguations. The name used by expert.ai to designate an entry in a Knowledge Graph is syncon .","title":"Knowledge Graph"},{"location":"guide/knowledgegraph/#the-knowledge-graph","text":"The expert.ai Knowledge Graph is a concept-based representation of universal or domain-specific knowledge for a given language. Each entry in the Knowledge Graph corresponds to a concept. There are entries for common nouns, proper nouns, verbs, adjectives and adverbs. Each entry contains information, for example: The terms that can be used to express the concept in a text, for example hand, pass, pass on, hand off, turn over, reach . the corresponding part-of-speech\u2014for example (to) climb \u2192 verb\u2014and other grammatical information on the terms. The topics to which the concept corresponds, for example soprano \u2192 opera, singing. References to external knowledge bases such as Wikidata, DBpedia, GeoNames, etc. Extended proprieties, for example the coordinates of places. Modeling concepts that can be expressed in a language are not sufficient to enable the text analysis software to interpret ambiguous terms alone. For example, consider that in the expert.ai universal Knowledge Graph for the English language there are more than 20 entries for the verb (to) put . The single entry has statistical information indicating the frequency with which the concept is used in a reference corpus compared to other concepts that can be expressed with the same word. This information is useful for disambiguation, but insufficient. Using statistics alone can lead to incorrect interpretations and to a textual analysis of low quality and even lower usefulness. What really improves the results are the relationships between concepts, hence the term Knowledge Graph . A single entry is linked to one or more other entries and, as such, relationships can be numerous. For example, a concept can be connected to other concepts in the hierarchical relationship called \"IS-A\". So: sodium IS A alkaline metal IS A metal IS A element Or there can be a \"part-whole\" relationship: wheel IS A PART OF car clutch IS A PART OF car dashboard IS A PART OF car Relationships are designed to be navigated in both directions, so from the concept of car it is possible to discover the parts that make it up (wheels, clutch, dashboard, etc.) by navigating the \"IS PART OF\" relationships downstream. In the same way, for the \"IS-A\" relationship, starting from the concept of alkaline metal it is possible to discover which elements are \"types of\" the parent concept (sodium, cesium, lithium, etc.). Relationships can be one-to-many. If this is obvious for the \"part-whole\" relations if read from the \"whole\" to the parts and for the \"IS A\" relationship if read from the more generic concept to the more specific ones, it is not obvious in the opposite direction. However it can be, for example: cat IS A feline but also: cat IS A pet So it is possible that in a hierarchical relationship a concept can have multiple \"parents\". The relationships between Knowledge Graph entries are the foundations of solid disambiguation. Suppose the text contains a form of the verb (to) put . As stated, the standard English Knowledge Graph contains more than 20 different concepts that can be expressed with (to) put , but which is the right one? Relationships can help. The text analysis software can explore the relationships of each concept to find out if the concept itself is linked to other concepts expressed in the same text. The concept with more links to other concepts is a good candidate for the \"right concept\". The disambiguation of one word helps to disambiguate the others, but the text analysis software is always free to \"go back\" and correct its previous clarification choices as it proceeds with the analysis of the other words of the text, with a chain effect on other disambiguations. The name used by expert.ai to designate an entry in a Knowledge Graph is syncon .","title":"The Knowledge Graph"},{"location":"guide/linguistic-analysis/","text":"Deep linguistic analysis overview Deep linguistic analysis is a type of document analysis that combines the following interdependent processes: Text subdivision Part-of-speech tagging Morphological analysis Lemmatization Syntactic analysis Semantic analysis The analysis is \"deep\" because, together with common linguistic analysis, it also: Disambiguates the terms of the text, i.e. picks one of all the possible meanings. Performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames , etc.\u2014are returned for text tokens corresponding to concepts of the expert.ai Knowledge Graph. Info In the case of actual places, geographic coordinates are also provided. In the manual's reference section you will find all the information required to perform deep linguistic analysis, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Overview"},{"location":"guide/linguistic-analysis/#deep-linguistic-analysis-overview","text":"Deep linguistic analysis is a type of document analysis that combines the following interdependent processes: Text subdivision Part-of-speech tagging Morphological analysis Lemmatization Syntactic analysis Semantic analysis The analysis is \"deep\" because, together with common linguistic analysis, it also: Disambiguates the terms of the text, i.e. picks one of all the possible meanings. Performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames , etc.\u2014are returned for text tokens corresponding to concepts of the expert.ai Knowledge Graph. Info In the case of actual places, geographic coordinates are also provided. In the manual's reference section you will find all the information required to perform deep linguistic analysis, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Deep linguistic analysis overview"},{"location":"guide/linguistic-analysis/lemmatization/","text":"Lemmatization Lemmatization is the deep linguistic analysis process that tags tokens and atoms with their corresponding lemmas . For example, for this sentence: Michael Jordan was one of the best basketball players of all time. lemmatization produces this output for detected tokens: Token Lemma Michael Jordan Michael Jordan was (to) be one one of of the the best good basketball players basketball player of of all all time time . n/a In the case of collocations, lemmatization is also applied to constituent atoms. For example the token: basketball players is a collocation composed of two atoms, for which lemmas are: basketball player In the case of anaphoras , the lemma is that of the antecedent or postcedent. For example, in the following text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. lemmatization recognizes Jordan and he in the second sentence as anaphoras, both of which have Michael Jordan as their antecedent in the first sentence, so the returned lemma for the anaphoras will be Michael Jordan . Lemmatization output is part of the JSON object returned by deep linguistic analysis .","title":"Lemmatization"},{"location":"guide/linguistic-analysis/lemmatization/#lemmatization","text":"Lemmatization is the deep linguistic analysis process that tags tokens and atoms with their corresponding lemmas . For example, for this sentence: Michael Jordan was one of the best basketball players of all time. lemmatization produces this output for detected tokens: Token Lemma Michael Jordan Michael Jordan was (to) be one one of of the the best good basketball players basketball player of of all all time time . n/a In the case of collocations, lemmatization is also applied to constituent atoms. For example the token: basketball players is a collocation composed of two atoms, for which lemmas are: basketball player In the case of anaphoras , the lemma is that of the antecedent or postcedent. For example, in the following text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. lemmatization recognizes Jordan and he in the second sentence as anaphoras, both of which have Michael Jordan as their antecedent in the first sentence, so the returned lemma for the anaphoras will be Michael Jordan . Lemmatization output is part of the JSON object returned by deep linguistic analysis .","title":"Lemmatization"},{"location":"guide/linguistic-analysis/morphological-analysis/","text":"Morphological analysis Morphological analysis is the deep linguistic analysis process that determines lexical and grammatical features of each token in addition to the part-of-speech . The result of the analysis is a list of Universal features . For example, the morphological analysis of the first token of this sentence: I saw a dandelion on my lawn. gives: Case=Nom|Number=Sing|Person=1|PronType=Prs which is a list of feature-value pairs corresponding to: Pair Feature label Feature description Value label Value description Case=Nom Case Case Nom Nominative Number=Sing Number Number Sing Singular Person=1 Person Person 1 First PronType=Prs PronType Pronoun type Prs Personal Morphological analysis output is part of the JSON object returned by deep linguistic analysis .","title":"Morphological analysis"},{"location":"guide/linguistic-analysis/morphological-analysis/#morphological-analysis","text":"Morphological analysis is the deep linguistic analysis process that determines lexical and grammatical features of each token in addition to the part-of-speech . The result of the analysis is a list of Universal features . For example, the morphological analysis of the first token of this sentence: I saw a dandelion on my lawn. gives: Case=Nom|Number=Sing|Person=1|PronType=Prs which is a list of feature-value pairs corresponding to: Pair Feature label Feature description Value label Value description Case=Nom Case Case Nom Nominative Number=Sing Number Number Sing Singular Person=1 Person Person 1 First PronType=Prs PronType Pronoun type Prs Personal Morphological analysis output is part of the JSON object returned by deep linguistic analysis .","title":"Morphological analysis"},{"location":"guide/linguistic-analysis/pos-tagging/","text":"Part-of-speech tagging Standard tagging Standard part-of-speech tagging is the deep linguistic analysis process that marks up each token with the corresponding Universal POS tag . For example, for this sentence: Michael Jordan was one of the best basketball players of all time. standard part-of-speech tagging produces this output: Token Part-of-speech Universal POS tag Michael Jordan Proper noun PROPN was Auxiliary AUX one Numeral NUM of Adposition ADP the Determiner DET best Adjective ADJ basketball players Noun NOUN of Adposition ADP all Determiner DET time Noun NOUN . Punctuation PUNCT Standard part-of-speech tagging output is part of the JSON object returned by deep linguistic analysis . Custom tagging In addition to standard part-of-speech tagging, deep linguistic analysis marks up both tokens and atoms with custom expert.ai type labels . expert.ai types combine part-of-speech information with entity type information. For example, for the following sentence: Please Travis, take me to Avalon. Do you mind if I bring my dog Bella with me? custom tagging is: Token Type description Custom expert.ai label Please Adverb ADV Travis Proper name of a human being NPR.NPH , Punctuation PNT take Verb VER me Pronoun PRO to Preposition PRE Avalon Proper noun of an extra-terrestrial or imaginary place GEX . Punctuation PNT Do Auxiliary verb AUX you Pronoun PRO mind Verb VER if Conjunction CON I Pronoun PRO bring Verb VER my Adjective ADJ dog Noun NOU Bella Proper noun of an animal NPR.ANM with Preposition PRE me Pronoun PRO ? Punctuation PNT As mentioned above, the expert.ai type is also attributed to atoms, while standard part-of-speech tagging stops at the token level. Custom part-of-speech tagging output is part of the JSON object returned by deep linguistic analysis .","title":"Part-of-speech tagging"},{"location":"guide/linguistic-analysis/pos-tagging/#part-of-speech-tagging","text":"","title":"Part-of-speech tagging"},{"location":"guide/linguistic-analysis/pos-tagging/#standard-tagging","text":"Standard part-of-speech tagging is the deep linguistic analysis process that marks up each token with the corresponding Universal POS tag . For example, for this sentence: Michael Jordan was one of the best basketball players of all time. standard part-of-speech tagging produces this output: Token Part-of-speech Universal POS tag Michael Jordan Proper noun PROPN was Auxiliary AUX one Numeral NUM of Adposition ADP the Determiner DET best Adjective ADJ basketball players Noun NOUN of Adposition ADP all Determiner DET time Noun NOUN . Punctuation PUNCT Standard part-of-speech tagging output is part of the JSON object returned by deep linguistic analysis .","title":"Standard tagging"},{"location":"guide/linguistic-analysis/pos-tagging/#custom-tagging","text":"In addition to standard part-of-speech tagging, deep linguistic analysis marks up both tokens and atoms with custom expert.ai type labels . expert.ai types combine part-of-speech information with entity type information. For example, for the following sentence: Please Travis, take me to Avalon. Do you mind if I bring my dog Bella with me? custom tagging is: Token Type description Custom expert.ai label Please Adverb ADV Travis Proper name of a human being NPR.NPH , Punctuation PNT take Verb VER me Pronoun PRO to Preposition PRE Avalon Proper noun of an extra-terrestrial or imaginary place GEX . Punctuation PNT Do Auxiliary verb AUX you Pronoun PRO mind Verb VER if Conjunction CON I Pronoun PRO bring Verb VER my Adjective ADJ dog Noun NOU Bella Proper noun of an animal NPR.ANM with Preposition PRE me Pronoun PRO ? Punctuation PNT As mentioned above, the expert.ai type is also attributed to atoms, while standard part-of-speech tagging stops at the token level. Custom part-of-speech tagging output is part of the JSON object returned by deep linguistic analysis .","title":"Custom tagging"},{"location":"guide/linguistic-analysis/semantic-analysis/","text":"Semantic analysis Semantic analysis is the deep linguistic analysis process that maps tokens to Knowledge Graph entries. This, together with knowledge linking, is what makes linguistic analysys \"deep\", because it attributes a meaning to each term of the text. Note : tokens corresponding to parts-of-speech like punctuation, conjunctions, articles, prepositions and pronouns are not mapped to Knowledge Graph entries. That isn't because they lack meaning, but because part-of-speech tagging and morphological analysis already provide enough information. Meaning attribution is a relatively easy task if a term is unambiguous. The problem arises when a term has multiple meanings . For example take the word: banks which can be interpreted as: Simple present tense, third person singular of the verb to bank in the sense of \"to deposit in a bank\" Plural form of the noun bank in the sense of \"financial institution\" Plural form of the noun bank in the sense of \"slope beside a body of water\" and more. In this case automatic disambiguation is needed, and this is the precisely what semantic analysis does using the Knowledge Graph and the relationships it contains. Semantic analysis output is part of the JSON object returned by deep linguistic analysis .","title":"Semantic analysis"},{"location":"guide/linguistic-analysis/semantic-analysis/#semantic-analysis","text":"Semantic analysis is the deep linguistic analysis process that maps tokens to Knowledge Graph entries. This, together with knowledge linking, is what makes linguistic analysys \"deep\", because it attributes a meaning to each term of the text. Note : tokens corresponding to parts-of-speech like punctuation, conjunctions, articles, prepositions and pronouns are not mapped to Knowledge Graph entries. That isn't because they lack meaning, but because part-of-speech tagging and morphological analysis already provide enough information. Meaning attribution is a relatively easy task if a term is unambiguous. The problem arises when a term has multiple meanings . For example take the word: banks which can be interpreted as: Simple present tense, third person singular of the verb to bank in the sense of \"to deposit in a bank\" Plural form of the noun bank in the sense of \"financial institution\" Plural form of the noun bank in the sense of \"slope beside a body of water\" and more. In this case automatic disambiguation is needed, and this is the precisely what semantic analysis does using the Knowledge Graph and the relationships it contains. Semantic analysis output is part of the JSON object returned by deep linguistic analysis .","title":"Semantic analysis"},{"location":"guide/linguistic-analysis/subdivision/","text":"Text subdivision The text subdivision process is the part of the deep linguistic analysis that detects text structure in terms of: Paragraphs Sentences Phrases Tokens Atoms During this process, the phrase type is also determined. A token can be: A collocation , a sequence of consecutive words recognized as a unit, like credit card or red carpet . A single word A punctuation mark By definition, an atom is something that cannot be further divided. The term is used here to indicate the single words that compose a token. As an example of text subdivision, consider this text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. Michael Jordan was also a baseball player and an actor. It gets divided in two paragraphs: 1. Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. 2. Michael Jordan was also a baseball player and an actor. The first paragraph is divided in two sentences: 1. Michael Jordan was one of the best basketball players of all time. 2. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. The first sentence is divided in six phrases: 1. Michael Jordan 2. was 3. one 4. of the best basketball players 5. of all time 6. . The fourth phrase is divided into four tokens: 1. of 2. the 3. best 4. basketball players Since (in the case of single-word tokens) atoms and tokens coincide, atoms are returned only for collocations , so only the fourth token is divided in two atoms: 1. basketball 2. player For each subdivision the process returns: Its position in the text The reference to the lower level constituent subdivisions Text subdivision output is part of the JSON object returned by deep linguistic analysis .","title":"Text subdivision"},{"location":"guide/linguistic-analysis/subdivision/#text-subdivision","text":"The text subdivision process is the part of the deep linguistic analysis that detects text structure in terms of: Paragraphs Sentences Phrases Tokens Atoms During this process, the phrase type is also determined. A token can be: A collocation , a sequence of consecutive words recognized as a unit, like credit card or red carpet . A single word A punctuation mark By definition, an atom is something that cannot be further divided. The term is used here to indicate the single words that compose a token. As an example of text subdivision, consider this text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. Michael Jordan was also a baseball player and an actor. It gets divided in two paragraphs: 1. Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. 2. Michael Jordan was also a baseball player and an actor. The first paragraph is divided in two sentences: 1. Michael Jordan was one of the best basketball players of all time. 2. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. The first sentence is divided in six phrases: 1. Michael Jordan 2. was 3. one 4. of the best basketball players 5. of all time 6. . The fourth phrase is divided into four tokens: 1. of 2. the 3. best 4. basketball players Since (in the case of single-word tokens) atoms and tokens coincide, atoms are returned only for collocations , so only the fourth token is divided in two atoms: 1. basketball 2. player For each subdivision the process returns: Its position in the text The reference to the lower level constituent subdivisions Text subdivision output is part of the JSON object returned by deep linguistic analysis .","title":"Text subdivision"},{"location":"guide/linguistic-analysis/syntactic-analysis/","text":"Syntactic analysis In the context of deep linguistic analysis , syntactic analysis is the parsing process that detects the universal dependency relation between each token and the sentence root token or another token. The process assigns a dependency relation label to each token. For example, for this sentence: The company has developed an entirely new category of products. syntactic analysis determines the head token index and the dependency label as follows: Token index Token text Head token index Universal dependency label 0 The 1 det 1 company 3 nsubj 2 has 3 aux 3 developed 3 root 4 an 7 det 5 entirely 7 advmod 6 new 7 amod 7 category 3 obj 8 of 9 case 9 product 7 nmod 10 . 3 punct Syntactic analysis output is part of the JSON object returned by deep linguistic analysis . Dependencies can be represented in various ways , such as a tree or arrow arcs .","title":"Syntactic analysis"},{"location":"guide/linguistic-analysis/syntactic-analysis/#syntactic-analysis","text":"In the context of deep linguistic analysis , syntactic analysis is the parsing process that detects the universal dependency relation between each token and the sentence root token or another token. The process assigns a dependency relation label to each token. For example, for this sentence: The company has developed an entirely new category of products. syntactic analysis determines the head token index and the dependency label as follows: Token index Token text Head token index Universal dependency label 0 The 1 det 1 company 3 nsubj 2 has 3 aux 3 developed 3 root 4 an 7 det 5 entirely 7 advmod 6 new 7 amod 7 category 3 obj 8 of 9 case 9 product 7 nmod 10 . 3 punct Syntactic analysis output is part of the JSON object returned by deep linguistic analysis . Dependencies can be represented in various ways , such as a tree or arrow arcs .","title":"Syntactic analysis"},{"location":"guide/relation-extraction/","text":"Relation extraction Relation extraction is a type of document analysis that labels concepts expressed in the text with their semantic role . Relation extraction also performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned for relation items corresponding to syncons of the expert.ai Knowledge Graph. In the case of actual places, geographic coordinates are also provided. In the reference section of this manual you will find all the information you need to perform relations extraction, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Relation extraction"},{"location":"guide/relation-extraction/#relation-extraction","text":"Relation extraction is a type of document analysis that labels concepts expressed in the text with their semantic role . Relation extraction also performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned for relation items corresponding to syncons of the expert.ai Knowledge Graph. In the case of actual places, geographic coordinates are also provided. In the reference section of this manual you will find all the information you need to perform relations extraction, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Relation extraction"},{"location":"guide/sentiment-analysis/","text":"Sentiment analysis Sentiment analysis is a type of document analysis that determines how positive or negative the tone of the text is. Sentiment analysis also performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned for text items that express sentiment given they correspond to syncons of the expert.ai Knowledge Graph. In the case of actual places, geographic coordinates are also provided. In the reference section of this manual you will find all the information you need to perform sentiment analysis, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Sentiment analysis"},{"location":"guide/sentiment-analysis/#sentiment-analysis","text":"Sentiment analysis is a type of document analysis that determines how positive or negative the tone of the text is. Sentiment analysis also performs knowledge linking: Knowledge Graph information and open data\u2014references to Wikidata, DBpedia, GeoNames, etc.\u2014are returned for text items that express sentiment given they correspond to syncons of the expert.ai Knowledge Graph. In the case of actual places, geographic coordinates are also provided. In the reference section of this manual you will find all the information you need to perform sentiment analysis, specifically: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Sentiment analysis"},{"location":"guide/templates/","text":"Templates A template is the set of fields that information extraction can fill with data to create records. The essex API provides a self-documentation resource returning all the defined templates. Note This resource is useful\u2014and meaningful\u2014only if the text intelligence engine has been programmed to perform information extraction. It must be requested using the POST method. In the reference section of this manual you will find: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Templates"},{"location":"guide/templates/#templates","text":"A template is the set of fields that information extraction can fill with data to create records. The essex API provides a self-documentation resource returning all the defined templates. Note This resource is useful\u2014and meaningful\u2014only if the text intelligence engine has been programmed to perform information extraction. It must be requested using the POST method. In the reference section of this manual you will find: The endpoint of the API resource to request. The format of the JSON object to send together with the request. The format of the JSON object returned.","title":"Templates"},{"location":"installation/","text":"Installation Ask your expert.ai representative for the essex installation package that best suits your needs. It could be for example an installer program that registers essex as an operating system service (under Windows) or daemon (under Linux), a Docker image or a portable folder containing the executable file.","title":"Installation"},{"location":"installation/#installation","text":"Ask your expert.ai representative for the essex installation package that best suits your needs. It could be for example an installer program that registers essex as an operating system service (under Windows) or daemon (under Linux), a Docker image or a portable folder containing the executable file.","title":"Installation"},{"location":"reference/","text":"REST interface reference Requests The JSON objects to send to the API HTTP status codes The codes the API can return Output Description of the API resources, i.e. the structure of returned JSON objects Positions How to interpret text blocks' positioning data Entity types The types recognized by entity recognition Phrase types Phrase types detected by text subdivision Topics The Knowledge Graph topics detected by keyphrase extraction Expert.ai types Custom part-of-speech tags Dependency representation How to represent syntactic analysis output","title":"Contents"},{"location":"reference/#rest-interface-reference","text":"Requests The JSON objects to send to the API HTTP status codes The codes the API can return Output Description of the API resources, i.e. the structure of returned JSON objects Positions How to interpret text blocks' positioning data Entity types The types recognized by entity recognition Phrase types Phrase types detected by text subdivision Topics The Knowledge Graph topics detected by keyphrase extraction Expert.ai types Custom part-of-speech tags Dependency representation How to represent syntactic analysis output","title":"REST interface reference"},{"location":"reference/dependency-representation/","text":"Dependency representation Here is an example of representing dependencies\u2014the output of syntactic analysis \u2014with arrow arcs. If you perform the deep linguistic analysis of this sentence: The company has developed an entirely new category of products. you'll get a response like this: { \"content\" : \"The company has developed an entirely new category of products.\" , \"language\" : \"EN\" , \"tokens\" : [ { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 0 , \"end\" : 3 , \"type\" : \"ART\" , \"lemma\" : \"The\" , \"pos\" : \"DET\" , \"id\" : 0 , \"head\" : 1 , \"dep\" : \"det\" }, { \"syncon\" : \"noun.organization.company\" , \"start\" : 4 , \"end\" : 11 , \"type\" : \"NOU\" , \"lemma\" : \"company\" , \"pos\" : \"NOUN\" , \"id\" : 1 , \"head\" : 3 , \"dep\" : \"nsubj\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 12 , \"end\" : 15 , \"type\" : \"AUX\" , \"lemma\" : \"has\" , \"pos\" : \"AUX\" , \"id\" : 2 , \"head\" : 3 , \"dep\" : \"aux\" }, { \"syncon\" : \"verb.general_action.develop\" , \"start\" : 16 , \"end\" : 25 , \"type\" : \"VER\" , \"lemma\" : \"develop\" , \"pos\" : \"VERB\" , \"id\" : 3 , \"head\" : 3 , \"dep\" : \"root\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 26 , \"end\" : 28 , \"type\" : \"ART\" , \"lemma\" : \"an\" , \"pos\" : \"DET\" , \"id\" : 4 , \"head\" : 7 , \"dep\" : \"det\" }, { \"syncon\" : \"adv.manner.fully\" , \"start\" : 29 , \"end\" : 37 , \"type\" : \"ADV\" , \"lemma\" : \"entirely\" , \"pos\" : \"ADV\" , \"id\" : 5 , \"head\" : 7 , \"dep\" : \"advmod\" }, { \"syncon\" : \"adj.new\" , \"start\" : 38 , \"end\" : 41 , \"type\" : \"ADJ\" , \"lemma\" : \"new\" , \"pos\" : \"ADJ\" , \"id\" : 6 , \"head\" : 7 , \"dep\" : \"amod\" }, { \"syncon\" : \"noun.object_group.category\" , \"start\" : 42 , \"end\" : 50 , \"type\" : \"NOU\" , \"lemma\" : \"category\" , \"pos\" : \"NOUN\" , \"id\" : 7 , \"head\" : 3 , \"dep\" : \"obj\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 51 , \"end\" : 53 , \"type\" : \"PRE\" , \"lemma\" : \"of\" , \"pos\" : \"ADP\" , \"id\" : 8 , \"head\" : 9 , \"dep\" : \"case\" }, { \"syncon\" : \"noun.artifact.products\" , \"start\" : 54 , \"end\" : 62 , \"type\" : \"NOU\" , \"lemma\" : \"product\" , \"pos\" : \"NOUN\" , \"id\" : 9 , \"head\" : 7 , \"dep\" : \"nmod\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 62 , \"end\" : 63 , \"type\" : \"PNT\" , \"lemma\" : \".\" , \"pos\" : \"PUNCT\" , \"id\" : 10 , \"head\" : 3 , \"dep\" : \"punct\" } ], \"phrases\" : [ { \"tokens\" : [ 0 , 1 ], \"type\" : \"NP\" , \"start\" : 0 , \"end\" : 11 }, { \"tokens\" : [ 2 , 3 ], \"type\" : \"VP\" , \"start\" : 12 , \"end\" : 25 }, { \"tokens\" : [ 4 , 5 , 6 , 7 ], \"type\" : \"NP\" , \"start\" : 26 , \"end\" : 50 }, { \"tokens\" : [ 8 , 9 ], \"type\" : \"PP\" , \"start\" : 51 , \"end\" : 62 }, { \"tokens\" : [ 10 ], \"type\" : \"NA\" , \"start\" : 62 , \"end\" : 63 }, { \"tokens\" : [], \"type\" : \"CR\" , \"start\" : 63 , \"end\" : 63 } ], \"sentences\" : [ { \"phrases\" : [ 0 , 1 , 2 , 3 , 4 , 5 ], \"start\" : 0 , \"end\" : 63 } ], \"paragraphs\" : [ { \"sentences\" : [ 0 ], \"start\" : 0 , \"end\" : 63 } ] } Use the tokens array because it contains the dependency structure of the sentence. Create a box for each token. Label the box with the token text. This can be extracted from the value of the content property of the outer data object using the start and the end properties of the token. To decorate the box: You can assign a color corresponding to the part-of-speech, that is the value of the pos property. For example, you can use pink for verbs, light blue for nouns, etc. You can also put the part-of-speech tag as an additional label inside the box. You can create a tooltip with the token's lemma property. Put a special mark over the token with the property dep set to root For all the non-root tokens, draw a dependency arc starting from the box of the token which id property value is equal to the value of head property. For example, if the current token has head = 3, start drawing the arc from the box of the token with id = 3 and put the arrow head in the current token's box. Decorate the arcs with the names of the dependencies you find in the dep property and you're done.","title":"Dependency representation"},{"location":"reference/dependency-representation/#dependency-representation","text":"Here is an example of representing dependencies\u2014the output of syntactic analysis \u2014with arrow arcs. If you perform the deep linguistic analysis of this sentence: The company has developed an entirely new category of products. you'll get a response like this: { \"content\" : \"The company has developed an entirely new category of products.\" , \"language\" : \"EN\" , \"tokens\" : [ { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 0 , \"end\" : 3 , \"type\" : \"ART\" , \"lemma\" : \"The\" , \"pos\" : \"DET\" , \"id\" : 0 , \"head\" : 1 , \"dep\" : \"det\" }, { \"syncon\" : \"noun.organization.company\" , \"start\" : 4 , \"end\" : 11 , \"type\" : \"NOU\" , \"lemma\" : \"company\" , \"pos\" : \"NOUN\" , \"id\" : 1 , \"head\" : 3 , \"dep\" : \"nsubj\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 12 , \"end\" : 15 , \"type\" : \"AUX\" , \"lemma\" : \"has\" , \"pos\" : \"AUX\" , \"id\" : 2 , \"head\" : 3 , \"dep\" : \"aux\" }, { \"syncon\" : \"verb.general_action.develop\" , \"start\" : 16 , \"end\" : 25 , \"type\" : \"VER\" , \"lemma\" : \"develop\" , \"pos\" : \"VERB\" , \"id\" : 3 , \"head\" : 3 , \"dep\" : \"root\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 26 , \"end\" : 28 , \"type\" : \"ART\" , \"lemma\" : \"an\" , \"pos\" : \"DET\" , \"id\" : 4 , \"head\" : 7 , \"dep\" : \"det\" }, { \"syncon\" : \"adv.manner.fully\" , \"start\" : 29 , \"end\" : 37 , \"type\" : \"ADV\" , \"lemma\" : \"entirely\" , \"pos\" : \"ADV\" , \"id\" : 5 , \"head\" : 7 , \"dep\" : \"advmod\" }, { \"syncon\" : \"adj.new\" , \"start\" : 38 , \"end\" : 41 , \"type\" : \"ADJ\" , \"lemma\" : \"new\" , \"pos\" : \"ADJ\" , \"id\" : 6 , \"head\" : 7 , \"dep\" : \"amod\" }, { \"syncon\" : \"noun.object_group.category\" , \"start\" : 42 , \"end\" : 50 , \"type\" : \"NOU\" , \"lemma\" : \"category\" , \"pos\" : \"NOUN\" , \"id\" : 7 , \"head\" : 3 , \"dep\" : \"obj\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 51 , \"end\" : 53 , \"type\" : \"PRE\" , \"lemma\" : \"of\" , \"pos\" : \"ADP\" , \"id\" : 8 , \"head\" : 9 , \"dep\" : \"case\" }, { \"syncon\" : \"noun.artifact.products\" , \"start\" : 54 , \"end\" : 62 , \"type\" : \"NOU\" , \"lemma\" : \"product\" , \"pos\" : \"NOUN\" , \"id\" : 9 , \"head\" : 7 , \"dep\" : \"nmod\" }, { \"syncon\" : \"noun.concepts.cause\" , \"start\" : 62 , \"end\" : 63 , \"type\" : \"PNT\" , \"lemma\" : \".\" , \"pos\" : \"PUNCT\" , \"id\" : 10 , \"head\" : 3 , \"dep\" : \"punct\" } ], \"phrases\" : [ { \"tokens\" : [ 0 , 1 ], \"type\" : \"NP\" , \"start\" : 0 , \"end\" : 11 }, { \"tokens\" : [ 2 , 3 ], \"type\" : \"VP\" , \"start\" : 12 , \"end\" : 25 }, { \"tokens\" : [ 4 , 5 , 6 , 7 ], \"type\" : \"NP\" , \"start\" : 26 , \"end\" : 50 }, { \"tokens\" : [ 8 , 9 ], \"type\" : \"PP\" , \"start\" : 51 , \"end\" : 62 }, { \"tokens\" : [ 10 ], \"type\" : \"NA\" , \"start\" : 62 , \"end\" : 63 }, { \"tokens\" : [], \"type\" : \"CR\" , \"start\" : 63 , \"end\" : 63 } ], \"sentences\" : [ { \"phrases\" : [ 0 , 1 , 2 , 3 , 4 , 5 ], \"start\" : 0 , \"end\" : 63 } ], \"paragraphs\" : [ { \"sentences\" : [ 0 ], \"start\" : 0 , \"end\" : 63 } ] } Use the tokens array because it contains the dependency structure of the sentence. Create a box for each token. Label the box with the token text. This can be extracted from the value of the content property of the outer data object using the start and the end properties of the token. To decorate the box: You can assign a color corresponding to the part-of-speech, that is the value of the pos property. For example, you can use pink for verbs, light blue for nouns, etc. You can also put the part-of-speech tag as an additional label inside the box. You can create a tooltip with the token's lemma property. Put a special mark over the token with the property dep set to root For all the non-root tokens, draw a dependency arc starting from the box of the token which id property value is equal to the value of head property. For example, if the current token has head = 3, start drawing the arc from the box of the token with id = 3 and put the arrow head in the current token's box. Decorate the arcs with the names of the dependencies you find in the dep property and you're done.","title":"Dependency representation"},{"location":"reference/endpoints/","text":"API endpoints The endpoints of the essex API are the addresses\u2014or URLs\u2014of its resources. Together with the JSON object that makes up the payload of each request, they identify exactly the resource that the API should return. The first part of the endpoint, being an URL, is always the protocol, host and port specification, for example: https://somehost:6699 This part corresponds to the essex Web service that is listening on the specified TCP port. The remainder of the endpoint is the resource path and it varies based on the type of functionality required: All text analysis resources, whether document analysis , document classification or information extraction , share this path: /api/analyze Self-documentation resources\u2014 categories' tree , templates \u2014have this path: /api/model","title":"Endpoints"},{"location":"reference/endpoints/#api-endpoints","text":"The endpoints of the essex API are the addresses\u2014or URLs\u2014of its resources. Together with the JSON object that makes up the payload of each request, they identify exactly the resource that the API should return. The first part of the endpoint, being an URL, is always the protocol, host and port specification, for example: https://somehost:6699 This part corresponds to the essex Web service that is listening on the specified TCP port. The remainder of the endpoint is the resource path and it varies based on the type of functionality required: All text analysis resources, whether document analysis , document classification or information extraction , share this path: /api/analyze Self-documentation resources\u2014 categories' tree , templates \u2014have this path: /api/model","title":"API endpoints"},{"location":"reference/entity-types/","text":"Entity types Here is the list of possible types that can be returned by named entity recognition and relation extraction . Uppercase labels are used for named entities. If the label is lowercase, and this can be given in the attributes of named entities or in the elements related to the verb in a relation, it means it is a generic entity. For example, in the text Felipe is a florist. florist can be labeled nph because a florist is a person, but not a specific one. Felipe , on the other hand, is a specific person identified by a proper name, so he is labeled with NPH . Label Description Example ADR Street address Who lived at 221B Baker Street ? ANM Animal Felix is an anthropomorphic black cat. BLD Building While in London I attended a concert at the Royal Albert Hall . COM Company, business Tesla Inc. sold 10% of its Bitcoin holdings. DAT Date Napoleon died on May 5, 1821 . DEV Device My new Galaxy smartphone has seven cameras. DOC Document I appeal to the Geneva Convention ! EVN Event Eddy Merckx won the Tour de France five times.. FDD Food, beverage Frank likes to drink Guinness beer. GEA Physical geographic feature I crossed the Mississipi river with my boat GEO Administrative geographic area Alaska is the least densely populated state in the United States . GEX Extended geography The astronauts have landed on Mars . HOU Hours The eclipse reached its peak at 3pm . LEN Legal entity Of course I pay the FICA tax. MAI Email address For any questions do not hesitate to write to helpme@somedomain.com . MEA Measure The chest is five feet wide and 40 inches tall. MMD Mass media I read it in the Guardian . MON Money I sold half of my stock and made six hundred thousand dollars . NPH Person Hakeem Olajuwon dunked effortlessly. NPR Unrecognized entity with a proper noun I like GYYYJJJ7 soooo much! ORG Organization, institution, society Now they threaten to quit the United Nations if they are not heard. PCT Percentage The richest 10% of adults in the world own 85% of global wealth. PHO Phone number For poor database design, call (214) 748-3647 . PPH Physical phenomena The COVID-19 infection is slowing down. PRD Product The Rolex Daytona is an wonderful watch. VCL Vehicle A Ferrari 250 GTO was the most expensive car ever sold. WEB Web address Find the best technical documentation at docs.expert.ai . WRK Work of human intelligence Grease is a funny musical romantic comedy.","title":"Entity types"},{"location":"reference/entity-types/#entity-types","text":"Here is the list of possible types that can be returned by named entity recognition and relation extraction . Uppercase labels are used for named entities. If the label is lowercase, and this can be given in the attributes of named entities or in the elements related to the verb in a relation, it means it is a generic entity. For example, in the text Felipe is a florist. florist can be labeled nph because a florist is a person, but not a specific one. Felipe , on the other hand, is a specific person identified by a proper name, so he is labeled with NPH . Label Description Example ADR Street address Who lived at 221B Baker Street ? ANM Animal Felix is an anthropomorphic black cat. BLD Building While in London I attended a concert at the Royal Albert Hall . COM Company, business Tesla Inc. sold 10% of its Bitcoin holdings. DAT Date Napoleon died on May 5, 1821 . DEV Device My new Galaxy smartphone has seven cameras. DOC Document I appeal to the Geneva Convention ! EVN Event Eddy Merckx won the Tour de France five times.. FDD Food, beverage Frank likes to drink Guinness beer. GEA Physical geographic feature I crossed the Mississipi river with my boat GEO Administrative geographic area Alaska is the least densely populated state in the United States . GEX Extended geography The astronauts have landed on Mars . HOU Hours The eclipse reached its peak at 3pm . LEN Legal entity Of course I pay the FICA tax. MAI Email address For any questions do not hesitate to write to helpme@somedomain.com . MEA Measure The chest is five feet wide and 40 inches tall. MMD Mass media I read it in the Guardian . MON Money I sold half of my stock and made six hundred thousand dollars . NPH Person Hakeem Olajuwon dunked effortlessly. NPR Unrecognized entity with a proper noun I like GYYYJJJ7 soooo much! ORG Organization, institution, society Now they threaten to quit the United Nations if they are not heard. PCT Percentage The richest 10% of adults in the world own 85% of global wealth. PHO Phone number For poor database design, call (214) 748-3647 . PPH Physical phenomena The COVID-19 infection is slowing down. PRD Product The Rolex Daytona is an wonderful watch. VCL Vehicle A Ferrari 250 GTO was the most expensive car ever sold. WEB Web address Find the best technical documentation at docs.expert.ai . WRK Work of human intelligence Grease is a funny musical romantic comedy.","title":"Entity types"},{"location":"reference/expert-ai-types/","text":"Expert.ai types The following table lists the possible custom type labels that can be assigned to tokens and atoms by custom part-of-speech tagging . Label Description ADJ Adjective ADV Adverb ART Article AUX Auxiliary verb CON Conjunction NOU Noun NOU.ADR Street address NOU.DAT Date NOU.HOU Hour NOU.MAI Email address NOU.MEA Measure NOU.MON Money NOU.PCT Percentage NOU.PHO Phone number NOU.WEB Web address NPR Proper noun NPR.ANM Proper noun of an animal NPR.BLD Proper noun of a building NPR.COM Proper noun of a business/company NPR.DEV Proper noun of a device NPR.DOC Proper noun of a document NPR.EVN Proper noun of an event NPR.FDD Proper noun of a food/beverage NPR.GEA Proper noun of a physical geographic feature NPR.GEO Proper noun of an administrative geographic area NPR.GEX Proper noun of an extra-terrestrial or imaginary place NPR.LEN Proper noun of a legal/fiscal entity NPR.MMD Proper noun of a mass media NPR.NPH Proper noun of a human being NPR.ORG Proper noun of an organization/society/institution NPR.PPH Proper noun of a physical phenomena NPR.PRD Proper noun of a product NPR.VCL Proper noun of a vehicle NPR.WRK Proper noun of a work of human intelligence PNT Punctuation mark PRE Preposition PRO Pronoun PRT Particle VER Verb","title":"expert.ai types"},{"location":"reference/expert-ai-types/#expertai-types","text":"The following table lists the possible custom type labels that can be assigned to tokens and atoms by custom part-of-speech tagging . Label Description ADJ Adjective ADV Adverb ART Article AUX Auxiliary verb CON Conjunction NOU Noun NOU.ADR Street address NOU.DAT Date NOU.HOU Hour NOU.MAI Email address NOU.MEA Measure NOU.MON Money NOU.PCT Percentage NOU.PHO Phone number NOU.WEB Web address NPR Proper noun NPR.ANM Proper noun of an animal NPR.BLD Proper noun of a building NPR.COM Proper noun of a business/company NPR.DEV Proper noun of a device NPR.DOC Proper noun of a document NPR.EVN Proper noun of an event NPR.FDD Proper noun of a food/beverage NPR.GEA Proper noun of a physical geographic feature NPR.GEO Proper noun of an administrative geographic area NPR.GEX Proper noun of an extra-terrestrial or imaginary place NPR.LEN Proper noun of a legal/fiscal entity NPR.MMD Proper noun of a mass media NPR.NPH Proper noun of a human being NPR.ORG Proper noun of an organization/society/institution NPR.PPH Proper noun of a physical phenomena NPR.PRD Proper noun of a product NPR.VCL Proper noun of a vehicle NPR.WRK Proper noun of a work of human intelligence PNT Punctuation mark PRE Preposition PRO Pronoun PRT Particle VER Verb","title":"Expert.ai types"},{"location":"reference/http-status-codes/","text":"HTTP status codes Status codes are part of the HTTP/HTTPS protocol and are issued by essex in response to a client's request. 200 OK The request has been accepted and processed. The response contains a JSON object . 400 Bad Request The server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax). It can happen when the JSON object posted with the request is invalid. 404 Not Found The server can not find the requested resource, the URL is wrong. 500 Internal Server Error The server has encountered a situation it doesn't know how to handle.","title":"HTTP status codes"},{"location":"reference/http-status-codes/#http-status-codes","text":"Status codes are part of the HTTP/HTTPS protocol and are issued by essex in response to a client's request.","title":"HTTP status codes"},{"location":"reference/http-status-codes/#200-ok","text":"The request has been accepted and processed. The response contains a JSON object .","title":"200 OK"},{"location":"reference/http-status-codes/#400-bad-request","text":"The server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax). It can happen when the JSON object posted with the request is invalid.","title":"400 Bad Request"},{"location":"reference/http-status-codes/#404-not-found","text":"The server can not find the requested resource, the URL is wrong.","title":"404 Not Found"},{"location":"reference/http-status-codes/#500-internal-server-error","text":"The server has encountered a situation it doesn't know how to handle.","title":"500 Internal Server Error"},{"location":"reference/output/","text":"API output Success In response to a request for a resource, in case of success, the API returns the HTTP 200 OK status and a UTF-8 encoded JSON object. All the analysis resources, whether document analysis , document classification or information extraction , share this output format: { \"success\": true, \"data\": { \"content\": analyzedtext , \"language\": languagecode , \"version\": engineinfo , resourcespecificproperties } } Self-documention resources have their peculiar output format . The value of the Boolean property success indicates that processing was successful while the data object contains the results of the analysis. The data object always has the following properties: content : the text that's been analyzed. language : the text language expressed as a ISO 639-1 language code . version : text intelligence engine information. After these properties, resource specific properties ( resourcespecificproperties ) follow. For more information about those properties, refer to the following articles: Document analysis: Full analysis Deep linguistic analysis Keyphrase extraction Named entity recognition Relation extraction Sentiment analysis Document classification Information extraction Managed errors In response to a request for a resource, in case of a managed error, the API returns the HTTP 200 OK status and a UTF-8 encoded JSON object with the following structure: { \"success\": false \"errors\": [ { \"code\": errorcode , \"message\": errormessage } ], } The value of the Boolean property success indicates that processing was not successful while the error object's properties code and message contain the error code and the error message respectively. For example, when the request for document analysis or classification resource is a JSON object without the text property, you get this object: { \"errors\" : [ { \"code\" : \"PREPARE_DOCUMENT_FAILED\" , \"message\" : \"missing layout key in json\" } ], \"success\" : false } Other errors In case of unmanaged application errors or other anomalies, the API returns specific HTTP status codes .","title":"Overview"},{"location":"reference/output/#api-output","text":"","title":"API output"},{"location":"reference/output/#success","text":"In response to a request for a resource, in case of success, the API returns the HTTP 200 OK status and a UTF-8 encoded JSON object. All the analysis resources, whether document analysis , document classification or information extraction , share this output format: { \"success\": true, \"data\": { \"content\": analyzedtext , \"language\": languagecode , \"version\": engineinfo , resourcespecificproperties } } Self-documention resources have their peculiar output format . The value of the Boolean property success indicates that processing was successful while the data object contains the results of the analysis. The data object always has the following properties: content : the text that's been analyzed. language : the text language expressed as a ISO 639-1 language code . version : text intelligence engine information. After these properties, resource specific properties ( resourcespecificproperties ) follow. For more information about those properties, refer to the following articles: Document analysis: Full analysis Deep linguistic analysis Keyphrase extraction Named entity recognition Relation extraction Sentiment analysis Document classification Information extraction","title":"Success"},{"location":"reference/output/#managed-errors","text":"In response to a request for a resource, in case of a managed error, the API returns the HTTP 200 OK status and a UTF-8 encoded JSON object with the following structure: { \"success\": false \"errors\": [ { \"code\": errorcode , \"message\": errormessage } ], } The value of the Boolean property success indicates that processing was not successful while the error object's properties code and message contain the error code and the error message respectively. For example, when the request for document analysis or classification resource is a JSON object without the text property, you get this object: { \"errors\" : [ { \"code\" : \"PREPARE_DOCUMENT_FAILED\" , \"message\" : \"missing layout key in json\" } ], \"success\" : false }","title":"Managed errors"},{"location":"reference/output/#other-errors","text":"In case of unmanaged application errors or other anomalies, the API returns specific HTTP status codes .","title":"Other errors"},{"location":"reference/output/classification/","text":"Document classification output The document classification resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"categories\": [] } } For the description of the contents , language and version properties, see output overview . Each item of the categories array represents a category, for example: { \"frequency\" : 70.62 , \"hierarchy\" : [ \"Sport\" , \"Competition discipline\" , \"Basketball\" ], \"id\" : \"20000851\" , \"label\" : \"Basketball\" , \"namespace\" : \"iptc_en_1.0\" , \"positions\" : [ { \"end\" : 14 , \"start\" : 0 }, { \"end\" : 53 , \"start\" : 35 }, { \"end\" : 139 , \"start\" : 136 } ], \"score\" : 4005.0 , \"winner\" : true } namespace is the name of the software module carrying out document classification inside the text intelligence engine. id , label and hierarchy identify the category in the categories' tree . score is the cumulative score that was attributed to the category. frequency is the percentage ratio of the category score to the sum of all categories' scores. Info Note that the sum of the frequencies of all categories could be less than 100. This occurs when the text intelligence engine is configured to filter out the \"losers\" categories. that is, those with the lowest scores. For further information on the topic of category score, consult the Studio documentation . winner is a Boolean flag set to true if the category was considered particularly relevant. positions is an array containing the positions of the text blocks that contributed to category score.","title":"Document classification"},{"location":"reference/output/classification/#document-classification-output","text":"The document classification resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"categories\": [] } } For the description of the contents , language and version properties, see output overview . Each item of the categories array represents a category, for example: { \"frequency\" : 70.62 , \"hierarchy\" : [ \"Sport\" , \"Competition discipline\" , \"Basketball\" ], \"id\" : \"20000851\" , \"label\" : \"Basketball\" , \"namespace\" : \"iptc_en_1.0\" , \"positions\" : [ { \"end\" : 14 , \"start\" : 0 }, { \"end\" : 53 , \"start\" : 35 }, { \"end\" : 139 , \"start\" : 136 } ], \"score\" : 4005.0 , \"winner\" : true } namespace is the name of the software module carrying out document classification inside the text intelligence engine. id , label and hierarchy identify the category in the categories' tree . score is the cumulative score that was attributed to the category. frequency is the percentage ratio of the category score to the sum of all categories' scores. Info Note that the sum of the frequencies of all categories could be less than 100. This occurs when the text intelligence engine is configured to filter out the \"losers\" categories. that is, those with the lowest scores. For further information on the topic of category score, consult the Studio documentation . winner is a Boolean flag set to true if the category was considered particularly relevant. positions is an array containing the positions of the text blocks that contributed to category score.","title":"Document classification output"},{"location":"reference/output/entity-recognition/","text":"Named entity recognition output The named entity recognition resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"entities\": [] } } For the description of the contents , language and version properties, see the API resources output overview . entities Each item of the entities array represents a named entity, for example: { \"lemma\" : \"National Basketball Association\" , \"positions\" : [ { \"end\" : 139 , \"start\" : 136 } ], \"relevance\" : 10 , \"syncon\" : 206693 , \"type\" : \"ORG\" , \"attributes\" : [ { \"attribute\" : \"role\" , \"lemma\" : \"league\" , \"syncon\" : 36253 , \"type\" : \"org\" } ] } type identifies the kind of entity. The possible values for type are listed in the reference section . positions is an array containing the positions of the entity's mentions in the text. The syncon and the lemma properties are the outcome of semantic analysis and lemmatization respectively. These are exactly the same processes carried out during deep linguistic analysis . Value -1 for syncon means the concept doesn't have a correspondent in the expert.ai Knowledge Graph . This can happen with entities that are recognized through heuristics (e.g. John Smith ). relevance is an indicator of the importance of the entity in text. It's values ranges from 1 to 15. attributes The attributes array contains information about the entities that is inferred by semantic analysis based on: Information available in the Knowledge Graph Semantic features of the entity's name The context in which the entity is cited The attribute property indicates the type of attribute. Possible values are: Value Description age Age of a person birthdate Birth date of a person birthplace Birth place of a person deathdate Death date of a person deathplace Death date of a person gender Gender of a person humanspec Specification of a person nationality Nationality of a person orgspec Specification of an organization placespec Specification of a place prodspec Specification of a product qualifyingadj Qualifying adjective qualifyingadv Qualifying adverb qualifyingnoun Qualifying noun role Role of an entity; if referred to a person can also be a title or a profession timerangespec Interval of time specification timespec Time specification Attributes can be nested, i.e. an attribute can have other attributes that further specify it. For example from the text: Saudi King Salman called on governments around the world these attributes are inferred for entity Salman : \"attributes\" : [ { \"attribute\" : \"gender\" , \"lemma\" : \"male\" , \"syncon\" : -1 , \"type\" : \"\" }, { \"attribute\" : \"role\" , \"lemma\" : \"King\" , \"syncon\" : 43350 , \"type\" : \"nph\" , \"attributes\" : [ { \"attribute\" : \"placespec\" , \"lemma\" : \"Saudi Arabia\" , \"syncon\" : 38596 , \"type\" : \"GEO\" } ], } ] The nested attribute, in this case, specifies the place of which entity Salman is the king, as if it were the answer to the question: \"king of what?\". For the syncon and lemma properties see above: they are the result of deep linguistic analysis. If the attribute is a generic or named entity, type identifies the kind of entity. Possible values can be uppercase or lowercase. Uppercase corresponds to named entities, lowercase to generic entities. knowledge The knowledge array contains Knowledge Graph data about the syncons associated with the entities. Its contents are described in the article about the output of full analysis .","title":"Named entity recognition"},{"location":"reference/output/entity-recognition/#named-entity-recognition-output","text":"The named entity recognition resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"entities\": [] } } For the description of the contents , language and version properties, see the API resources output overview .","title":"Named entity recognition output"},{"location":"reference/output/entity-recognition/#entities","text":"Each item of the entities array represents a named entity, for example: { \"lemma\" : \"National Basketball Association\" , \"positions\" : [ { \"end\" : 139 , \"start\" : 136 } ], \"relevance\" : 10 , \"syncon\" : 206693 , \"type\" : \"ORG\" , \"attributes\" : [ { \"attribute\" : \"role\" , \"lemma\" : \"league\" , \"syncon\" : 36253 , \"type\" : \"org\" } ] } type identifies the kind of entity. The possible values for type are listed in the reference section . positions is an array containing the positions of the entity's mentions in the text. The syncon and the lemma properties are the outcome of semantic analysis and lemmatization respectively. These are exactly the same processes carried out during deep linguistic analysis . Value -1 for syncon means the concept doesn't have a correspondent in the expert.ai Knowledge Graph . This can happen with entities that are recognized through heuristics (e.g. John Smith ). relevance is an indicator of the importance of the entity in text. It's values ranges from 1 to 15.","title":"entities"},{"location":"reference/output/entity-recognition/#attributes","text":"The attributes array contains information about the entities that is inferred by semantic analysis based on: Information available in the Knowledge Graph Semantic features of the entity's name The context in which the entity is cited The attribute property indicates the type of attribute. Possible values are: Value Description age Age of a person birthdate Birth date of a person birthplace Birth place of a person deathdate Death date of a person deathplace Death date of a person gender Gender of a person humanspec Specification of a person nationality Nationality of a person orgspec Specification of an organization placespec Specification of a place prodspec Specification of a product qualifyingadj Qualifying adjective qualifyingadv Qualifying adverb qualifyingnoun Qualifying noun role Role of an entity; if referred to a person can also be a title or a profession timerangespec Interval of time specification timespec Time specification Attributes can be nested, i.e. an attribute can have other attributes that further specify it. For example from the text: Saudi King Salman called on governments around the world these attributes are inferred for entity Salman : \"attributes\" : [ { \"attribute\" : \"gender\" , \"lemma\" : \"male\" , \"syncon\" : -1 , \"type\" : \"\" }, { \"attribute\" : \"role\" , \"lemma\" : \"King\" , \"syncon\" : 43350 , \"type\" : \"nph\" , \"attributes\" : [ { \"attribute\" : \"placespec\" , \"lemma\" : \"Saudi Arabia\" , \"syncon\" : 38596 , \"type\" : \"GEO\" } ], } ] The nested attribute, in this case, specifies the place of which entity Salman is the king, as if it were the answer to the question: \"king of what?\". For the syncon and lemma properties see above: they are the result of deep linguistic analysis. If the attribute is a generic or named entity, type identifies the kind of entity. Possible values can be uppercase or lowercase. Uppercase corresponds to named entities, lowercase to generic entities.","title":"attributes"},{"location":"reference/output/entity-recognition/#knowledge","text":"The knowledge array contains Knowledge Graph data about the syncons associated with the entities. Its contents are described in the article about the output of full analysis .","title":"knowledge"},{"location":"reference/output/extraction/","text":"Information exraction output The information extraction resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"extractions\": [] } } For the description of the contents , language and version properties, see output overview . Each item of the extractions array represents an extraction record, for example: \"extractions\" : [ { \"namespace\" : \"project01\" , \"template\" : \"RELATIONS\" , \"fields\" : [ { \"name\" : \"DISEASE\" , \"value\" : \"Diabetes\" , \"positions\" : [ { \"start\" : 1621 , \"end\" : 1629 } ] }, { \"name\" : \"DISEASE2\" , \"value\" : \"COVID-19\" , \"positions\" : [ { \"start\" : 1673 , \"end\" : 1684 } ] }, { \"name\" : \"RELATION\" , \"value\" : \"TR_RISK_FACTOR\" , \"positions\" : [ { \"start\" : 1642 , \"end\" : 1656 } ] } ] } ] namespace is the name of the software module carrying out information extraction inside the text intelligence engine. template is the name of the record's template fields is the array of record's fields. Each item of the fields array represents an extracted field, where: name is the field's name. value is the field's value. positions is an array containing the extracted field's positions . Info You can find more information about templates and fields in the Studio documentation .","title":"Information extraction"},{"location":"reference/output/extraction/#information-exraction-output","text":"The information extraction resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"extractions\": [] } } For the description of the contents , language and version properties, see output overview . Each item of the extractions array represents an extraction record, for example: \"extractions\" : [ { \"namespace\" : \"project01\" , \"template\" : \"RELATIONS\" , \"fields\" : [ { \"name\" : \"DISEASE\" , \"value\" : \"Diabetes\" , \"positions\" : [ { \"start\" : 1621 , \"end\" : 1629 } ] }, { \"name\" : \"DISEASE2\" , \"value\" : \"COVID-19\" , \"positions\" : [ { \"start\" : 1673 , \"end\" : 1684 } ] }, { \"name\" : \"RELATION\" , \"value\" : \"TR_RISK_FACTOR\" , \"positions\" : [ { \"start\" : 1642 , \"end\" : 1656 } ] } ] } ] namespace is the name of the software module carrying out information extraction inside the text intelligence engine. template is the name of the record's template fields is the array of record's fields. Each item of the fields array represents an extracted field, where: name is the field's name. value is the field's value. positions is an array containing the extracted field's positions . Info You can find more information about templates and fields in the Studio documentation .","title":"Information exraction output"},{"location":"reference/output/full-analysis/","text":"Full document analysis output The full analysis resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"paragraphs\": [], \"sentences\": [], \"phrases\": [], \"tokens\": [], \"mainSentences\": [], \"mainPhrases\": [], \"mainLemmas\": [], \"mainSyncons\": [], \"topics\": [], \"entities\": [], \"relations\": [], \"sentiment\": {} } } For the description of the contents , language and version properties, see the API output overview . Components arrays have the same structure they have in the response of the resource that performs the corresponding process, so: For: paragraphs sentences phrases tokens arrays see the format of deep linguistic analysis output . For: mainSentences mainPhrases mainLemmas mainSyncons topics arrays see the format of keyphrase extraction output . For: entities array see the format of named entity recognition output . For: relations array see the format of relation extraction output . For: sentiment object see the format of sentiment analysis output . knowledge The knowledge array contains Knowledge Graph data information about syncons. Items in these arrays: tokens manSyncons entities relations items (in the sentiment object) can have a syncon property: the link between those items and the corresponding items in the knowledge array is thus represented by the value of the syncon property both items have in common. For example, if this is an item of the tokens array: { \"atoms\" : [ { \"end\" : 45 , \"lemma\" : \"basketball\" , \"start\" : 35 , \"type\" : \"NOU\" }, { \"end\" : 53 , \"lemma\" : \"player\" , \"start\" : 46 , \"type\" : \"NOU\" } ], \"dependency\" : { \"head\" : 2 , \"id\" : 6 , \"label\" : \"nmod\" }, \"end\" : 53 , \"lemma\" : \"basketball player\" , \"morphology\" : \"Number=Plur\" , \"paragraph\" : 0 , \"phrase\" : 2 , \"pos\" : \"NOUN\" , \"sentence\" : 0 , \"start\" : 35 , \"syncon\" : 41583 , \"type\" : \"NOU\" } the corresponding entry in the knowledge array can be: { \"label\" : \"person.athlete.basketball_player\" , \"properties\" : [ { \"type\" : \"WikiDataId\" , \"value\" : \"Q3665646\" } ], \"syncon\" : 41583 } It can be a \"many-to-one\" relationship since more than one item in the tokens , relations and sentiment items arrays can have the same syncon ID, but there's always one entry in the knowledge array for a given syncon, so the knowledge array is a reference table. For example, if a text contains several occurrences of basketball player , each occurrence corresponds to a separate item in the tokens array, but all tokens \"point\" to the same entry in the knowledge array. Items with the syncon property set to -1 have no corresponding entry in the knowledge array. This is because they are concepts recognized through heuristics and are not present in the Knowledge Graph. Each entry in the array has a format like this: { \"label\" : \"person\" , \"properties\" : [ { \"type\" : \"WikiDataId\" , \"value\" : \"Q215627\" } ], \"syncon\" : 73282 } The label property is a textual rendering of the general conceptual category for the syncon in the Knowledge Graph. The properties array contains the outcome of knowledge linking. Each item has two properties, type and value . type specifies the knowledge base, value is the property value. Possible knowledge bases and interpretations of the value property follow. type value Coordinate Latitude and longitude WikiDataId Wikipedia article ID DBpediaId URL of the DBPedia content GeoNamesId ID of the record in the GeoNames database","title":"Full analysis"},{"location":"reference/output/full-analysis/#full-document-analysis-output","text":"The full analysis resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"paragraphs\": [], \"sentences\": [], \"phrases\": [], \"tokens\": [], \"mainSentences\": [], \"mainPhrases\": [], \"mainLemmas\": [], \"mainSyncons\": [], \"topics\": [], \"entities\": [], \"relations\": [], \"sentiment\": {} } } For the description of the contents , language and version properties, see the API output overview . Components arrays have the same structure they have in the response of the resource that performs the corresponding process, so: For: paragraphs sentences phrases tokens arrays see the format of deep linguistic analysis output . For: mainSentences mainPhrases mainLemmas mainSyncons topics arrays see the format of keyphrase extraction output . For: entities array see the format of named entity recognition output . For: relations array see the format of relation extraction output . For: sentiment object see the format of sentiment analysis output .","title":"Full document analysis output"},{"location":"reference/output/full-analysis/#knowledge","text":"The knowledge array contains Knowledge Graph data information about syncons. Items in these arrays: tokens manSyncons entities relations items (in the sentiment object) can have a syncon property: the link between those items and the corresponding items in the knowledge array is thus represented by the value of the syncon property both items have in common. For example, if this is an item of the tokens array: { \"atoms\" : [ { \"end\" : 45 , \"lemma\" : \"basketball\" , \"start\" : 35 , \"type\" : \"NOU\" }, { \"end\" : 53 , \"lemma\" : \"player\" , \"start\" : 46 , \"type\" : \"NOU\" } ], \"dependency\" : { \"head\" : 2 , \"id\" : 6 , \"label\" : \"nmod\" }, \"end\" : 53 , \"lemma\" : \"basketball player\" , \"morphology\" : \"Number=Plur\" , \"paragraph\" : 0 , \"phrase\" : 2 , \"pos\" : \"NOUN\" , \"sentence\" : 0 , \"start\" : 35 , \"syncon\" : 41583 , \"type\" : \"NOU\" } the corresponding entry in the knowledge array can be: { \"label\" : \"person.athlete.basketball_player\" , \"properties\" : [ { \"type\" : \"WikiDataId\" , \"value\" : \"Q3665646\" } ], \"syncon\" : 41583 } It can be a \"many-to-one\" relationship since more than one item in the tokens , relations and sentiment items arrays can have the same syncon ID, but there's always one entry in the knowledge array for a given syncon, so the knowledge array is a reference table. For example, if a text contains several occurrences of basketball player , each occurrence corresponds to a separate item in the tokens array, but all tokens \"point\" to the same entry in the knowledge array. Items with the syncon property set to -1 have no corresponding entry in the knowledge array. This is because they are concepts recognized through heuristics and are not present in the Knowledge Graph. Each entry in the array has a format like this: { \"label\" : \"person\" , \"properties\" : [ { \"type\" : \"WikiDataId\" , \"value\" : \"Q215627\" } ], \"syncon\" : 73282 } The label property is a textual rendering of the general conceptual category for the syncon in the Knowledge Graph. The properties array contains the outcome of knowledge linking. Each item has two properties, type and value . type specifies the knowledge base, value is the property value. Possible knowledge bases and interpretations of the value property follow. type value Coordinate Latitude and longitude WikiDataId Wikipedia article ID DBpediaId URL of the DBPedia content GeoNamesId ID of the record in the GeoNames database","title":"knowledge"},{"location":"reference/output/keyphrase-extraction/","text":"Keyphrase extraction output The keyphrase extraction resource returns a JSON object with this structure: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"topics\": [], \"mainSentences\": [], \"mainPhrases\": [], \"mainSyncons\": [], \"mainLemmas\": [] } } For the description of the contents , language and version properties see the API resources output overview . Common properties Items that can be directly mapped to the text have properties indicating their position . Items that occur only once, such as a sentence, have a start and end properties while items that can occur multiple times, such as a main lemma, have a positions array containing the start and end positions of all the occurrences. Items also have a score property which provides a measure of their relevance. topics The topics array contains references to Knowledge Graph topics pertinent with the text. Each array item corresponds to a topic, for example: { \"id\" : 223 , \"label\" : \"mechanics\" , \"score\" : 3.5 , \"winner\" : true } Possible topics are listed in the reference section . id is the identification number, winner is a Boolean flag set to true if the topic is considered particularly relevant. mainSentences The mainSentences array contains info about relevant sentences. Each array item represents a sentence, for example: { \"value\" : \"The machine is held until ready to start by a sort of trap to be sprung when all is ready; then with a tremendous flapping and snapping of the four-cylinder engine, the huge machine springs aloft.\" , \"score\" : 13.3 , \"start\" : 740 , \"end\" : 936 } mainPhrases The mainPhrases array contains info about the phrases deemed particularly representative during the analysis. Each array item represents a phrase, for example: { \"value\" : \"four-cylinder engine\" , \"score\" : 8 , \"positions\" : [ { \"start\" : 883 , \"end\" : 903 } ] } mainSyncons The mainSyncons array contains references to Knowledge Graph syncons corresponding to the concepts that were considered relevant. Each array item represents a syncon, for example: { \"lemma\" : \"experiment\" , \"positions\" : [ { \"end\" : 224 , \"start\" : 213 }, { \"end\" : 2830 , \"start\" : 2820 } ], \"score\" : 5.8 , \"syncon\" : 2496 } The syncon and the lemma properties are the outcome of semantic analysis and lemmatization respectively. These are exactly the same processes carried out during deep linguistic analysis . syncon can be interpreted as a pointer to the knowledge array entry having its syncon property set to the same value. mainLemmas The mainLemmas array contains relevant lemmas. Each array item represents a lemma, for example: { \"value\" : \"locomotive\" , \"score\" : 6.5 , \"positions\" : [ { \"start\" : 1152 , \"end\" : 1162 }, { \"start\" : 1163 , \"end\" : 1167 }, { \"start\" : 1239 , \"end\" : 1249 }, { \"start\" : 1335 , \"end\" : 1345 }, { \"start\" : 1394 , \"end\" : 1404 } ] } knowledge The knowledge array contains Knowledge Graph data for the items of the mainSyncons array. Its contents are described in the article about the output of full analysis .","title":"Keyphrase extraction"},{"location":"reference/output/keyphrase-extraction/#keyphrase-extraction-output","text":"The keyphrase extraction resource returns a JSON object with this structure: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"topics\": [], \"mainSentences\": [], \"mainPhrases\": [], \"mainSyncons\": [], \"mainLemmas\": [] } } For the description of the contents , language and version properties see the API resources output overview .","title":"Keyphrase extraction output"},{"location":"reference/output/keyphrase-extraction/#common-properties","text":"Items that can be directly mapped to the text have properties indicating their position . Items that occur only once, such as a sentence, have a start and end properties while items that can occur multiple times, such as a main lemma, have a positions array containing the start and end positions of all the occurrences. Items also have a score property which provides a measure of their relevance.","title":"Common properties"},{"location":"reference/output/keyphrase-extraction/#topics","text":"The topics array contains references to Knowledge Graph topics pertinent with the text. Each array item corresponds to a topic, for example: { \"id\" : 223 , \"label\" : \"mechanics\" , \"score\" : 3.5 , \"winner\" : true } Possible topics are listed in the reference section . id is the identification number, winner is a Boolean flag set to true if the topic is considered particularly relevant.","title":"topics"},{"location":"reference/output/keyphrase-extraction/#mainsentences","text":"The mainSentences array contains info about relevant sentences. Each array item represents a sentence, for example: { \"value\" : \"The machine is held until ready to start by a sort of trap to be sprung when all is ready; then with a tremendous flapping and snapping of the four-cylinder engine, the huge machine springs aloft.\" , \"score\" : 13.3 , \"start\" : 740 , \"end\" : 936 }","title":"mainSentences"},{"location":"reference/output/keyphrase-extraction/#mainphrases","text":"The mainPhrases array contains info about the phrases deemed particularly representative during the analysis. Each array item represents a phrase, for example: { \"value\" : \"four-cylinder engine\" , \"score\" : 8 , \"positions\" : [ { \"start\" : 883 , \"end\" : 903 } ] }","title":"mainPhrases"},{"location":"reference/output/keyphrase-extraction/#mainsyncons","text":"The mainSyncons array contains references to Knowledge Graph syncons corresponding to the concepts that were considered relevant. Each array item represents a syncon, for example: { \"lemma\" : \"experiment\" , \"positions\" : [ { \"end\" : 224 , \"start\" : 213 }, { \"end\" : 2830 , \"start\" : 2820 } ], \"score\" : 5.8 , \"syncon\" : 2496 } The syncon and the lemma properties are the outcome of semantic analysis and lemmatization respectively. These are exactly the same processes carried out during deep linguistic analysis . syncon can be interpreted as a pointer to the knowledge array entry having its syncon property set to the same value.","title":"mainSyncons"},{"location":"reference/output/keyphrase-extraction/#mainlemmas","text":"The mainLemmas array contains relevant lemmas. Each array item represents a lemma, for example: { \"value\" : \"locomotive\" , \"score\" : 6.5 , \"positions\" : [ { \"start\" : 1152 , \"end\" : 1162 }, { \"start\" : 1163 , \"end\" : 1167 }, { \"start\" : 1239 , \"end\" : 1249 }, { \"start\" : 1335 , \"end\" : 1345 }, { \"start\" : 1394 , \"end\" : 1404 } ] }","title":"mainLemmas"},{"location":"reference/output/keyphrase-extraction/#knowledge","text":"The knowledge array contains Knowledge Graph data for the items of the mainSyncons array. Its contents are described in the article about the output of full analysis .","title":"knowledge"},{"location":"reference/output/linguistic-analysis/","text":"Deep linguistic analysis output The deep linguistic analysis resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"tokens\": [], \"phrases\": [], \"sentences\": [], \"paragraphs\": [] } } For the description of the contents , language and version properties, see the API resources output overview . The knowledge array contains Knowledge Graph data as a result of the semantic analysis process. Its contents are described in the article about the output of full analysis . The paragraphs , sentences , phrases and tokens arrays are produced by the text subdivision process . The items of the tokens array are then enriched by the other deep linguistic analysis processes: part-of-speech tagging , morphological analysis , lemmatization , syntactic analysis and semantic analysis . The contents of these arrays are described below. tokens The tokens array contains an item for every token detected. Each item has a format like this: { \"syncon\" : 62653 , \"start\" : 74 , \"end\" : 83 , \"type\" : \"NOU\" , \"lemma\" : \"long time\" , \"pos\" : \"NOUN\" , \"dependency\" : { \"id\" : 11 , \"head\" : 7 , \"label\" : \"nmod\" }, \"morphology\" : \"Number=Sing\" , \"paragraph\" : 0 , \"sentence\" : 0 , \"phrase\" : 4 , \"atoms\" : [ { \"start\" : 74 , \"end\" : 78 , \"type\" : \"ADJ\" , \"lemma\" : \"long\" }, { \"start\" : 79 , \"end\" : 83 , \"type\" : \"NOU\" , \"lemma\" : \"time\" } ] } The syncon property is the outcome of the semantic analysis process. Its value is the ID of the corresponding syncon in the Knowledge Graph. The -1 value is attributed to tokens that do not have a corresponding syncon. A positive value has a match in the value of the syncon property of an entry in the knowledge array. type is the result of custom part-of-speech tagging . lemma is the result of lemmatization . pos is the result of standard part-of-speech tagging . dependency is the result of syntactic analysis . id represents the index of the token in the text. dep specifies the dependency relation with another token according to the Universal Dependencies conventions . head identifies the token that receives the relation the relation. Its value corresponds to the value of the id property of another token, the only exception being the root token \u2014the one with the dep property set to root \u2014for which head and id have the same value. morphology is the result of morphological analysis . start , end , phrase , sentence and paragraph are the result of text subdivision process . start and end are the positions of the token text in the analyzed text, which is the value of the content property of the outer data object. phrase is the phrase containing the token; it's the zero-based index of the phrase in the phrases array. sentence is the sentence containing the token; it's the zero-based index of the sentence in the sentences array. paragraph is the paragraph containing the token; it's the zero-based index of the paragraph in the paragraphs array. In the case of collocations, the token object can contain the atoms array. There's an item for every word of the collocation in the atoms array and in each item of the atoms array: start and end are the result of text subdivision process . They represent the positions of the atom text in the analyzed text, which is the value of the content property of the outer data object type is the the result of custom part-of-speech tagging . lemma property is the result of lemmatization for to the word. Sometimes the semantic analysis process determines that a token is a named entity\u2014for example: a person's name\u2014even if there is no corresponding concept in the Knowledge Graph. In this case the syncon property is set to -1, but the token has an additional vsyn property. For example: { \"syncon\" : -1 , \"vsyn\" : { \"id\" : -436106 , \"parent\" : 73303 }, \"start\" : 0 , \"end\" : 19 , \"type\" : \"NPR.NPH\" , \"lemma\" : \"Mauricio Pochettino\" , ... This property, whose name means \"virtual syncon\", is an object with two properties: id is a negative number generated by the semantic analysis process and assigned to all tokens considered as occurrences of the same entity. It is not the ID of a Knowledge Graph syncon. parent is the number of a Knowledge Graph syncon which, conceptually, is the parent of the concept expressed by the token. For example, if the token has been recognized as a person's name, its parent is the concept of person . The parent syncon data is located in the knowledge array. phrases The phrases array is created and populated by the text subdivision process. It contains an item for every phrase detected. For example, the phrase: Michael Jordan was one of the best basketball players of all time . corresponds to an array item like this: { \"tokens\" : [ 7 , 8 , 9 ], \"type\" : \"PP\" , \"start\" : 54 , \"end\" : 65 } The tokens array contains the zero-based indexes of the constituent tokens. For example, token 7 is the 8th token. type specifies the phrase type . start and end are the positions of the phrase in the analyzed text, which is the value of the content property of the outer data object. sentences The sentences array is created and populated by the text subdivision process. It contains an item for every sentence detected. For example, this sentence: Michael Jordan was one of the best basketball players of all time. corresponds to an array item like this: { \"phrases\" : [ 0 , 1 , 2 , 3 , 4 , 5 ], \"start\" : 0 , \"end\" : 66 } The phrases array contains the zero-based indexes of the constituent phrases. start and end are the positions of the sentence in the analyzed text, which is the value of the content property of the outer data object. paragraphs The paragraphs array is created and populated by the text subdivision process. It contains an item for every paragraph detected. For example this text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. Michael Jordan was also a baseball player and an actor. contains two paragraphs and the corresponding array is something like: \"paragraphs\" : [ { \"sentences\" : [ 0 , 1 ], \"start\" : 0 , \"end\" : 176 }, { \"sentences\" : [ 2 ], \"start\" : 177 , \"end\" : 232 } ] The sentences array in each item contains the zero-based indexes of the constituent sentences. start and end are the positions of the paragraph in the analyzed text, which is the value of the content property of the outer data object. knowledge The knowledge array contains Knowledge Graph data for the items of the tokens array. Its contents are described in the article about the output of full analysis .","title":"Deep linguistic analysis"},{"location":"reference/output/linguistic-analysis/#deep-linguistic-analysis-output","text":"The deep linguistic analysis resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"tokens\": [], \"phrases\": [], \"sentences\": [], \"paragraphs\": [] } } For the description of the contents , language and version properties, see the API resources output overview . The knowledge array contains Knowledge Graph data as a result of the semantic analysis process. Its contents are described in the article about the output of full analysis . The paragraphs , sentences , phrases and tokens arrays are produced by the text subdivision process . The items of the tokens array are then enriched by the other deep linguistic analysis processes: part-of-speech tagging , morphological analysis , lemmatization , syntactic analysis and semantic analysis . The contents of these arrays are described below.","title":"Deep linguistic analysis output"},{"location":"reference/output/linguistic-analysis/#tokens","text":"The tokens array contains an item for every token detected. Each item has a format like this: { \"syncon\" : 62653 , \"start\" : 74 , \"end\" : 83 , \"type\" : \"NOU\" , \"lemma\" : \"long time\" , \"pos\" : \"NOUN\" , \"dependency\" : { \"id\" : 11 , \"head\" : 7 , \"label\" : \"nmod\" }, \"morphology\" : \"Number=Sing\" , \"paragraph\" : 0 , \"sentence\" : 0 , \"phrase\" : 4 , \"atoms\" : [ { \"start\" : 74 , \"end\" : 78 , \"type\" : \"ADJ\" , \"lemma\" : \"long\" }, { \"start\" : 79 , \"end\" : 83 , \"type\" : \"NOU\" , \"lemma\" : \"time\" } ] } The syncon property is the outcome of the semantic analysis process. Its value is the ID of the corresponding syncon in the Knowledge Graph. The -1 value is attributed to tokens that do not have a corresponding syncon. A positive value has a match in the value of the syncon property of an entry in the knowledge array. type is the result of custom part-of-speech tagging . lemma is the result of lemmatization . pos is the result of standard part-of-speech tagging . dependency is the result of syntactic analysis . id represents the index of the token in the text. dep specifies the dependency relation with another token according to the Universal Dependencies conventions . head identifies the token that receives the relation the relation. Its value corresponds to the value of the id property of another token, the only exception being the root token \u2014the one with the dep property set to root \u2014for which head and id have the same value. morphology is the result of morphological analysis . start , end , phrase , sentence and paragraph are the result of text subdivision process . start and end are the positions of the token text in the analyzed text, which is the value of the content property of the outer data object. phrase is the phrase containing the token; it's the zero-based index of the phrase in the phrases array. sentence is the sentence containing the token; it's the zero-based index of the sentence in the sentences array. paragraph is the paragraph containing the token; it's the zero-based index of the paragraph in the paragraphs array. In the case of collocations, the token object can contain the atoms array. There's an item for every word of the collocation in the atoms array and in each item of the atoms array: start and end are the result of text subdivision process . They represent the positions of the atom text in the analyzed text, which is the value of the content property of the outer data object type is the the result of custom part-of-speech tagging . lemma property is the result of lemmatization for to the word. Sometimes the semantic analysis process determines that a token is a named entity\u2014for example: a person's name\u2014even if there is no corresponding concept in the Knowledge Graph. In this case the syncon property is set to -1, but the token has an additional vsyn property. For example: { \"syncon\" : -1 , \"vsyn\" : { \"id\" : -436106 , \"parent\" : 73303 }, \"start\" : 0 , \"end\" : 19 , \"type\" : \"NPR.NPH\" , \"lemma\" : \"Mauricio Pochettino\" , ... This property, whose name means \"virtual syncon\", is an object with two properties: id is a negative number generated by the semantic analysis process and assigned to all tokens considered as occurrences of the same entity. It is not the ID of a Knowledge Graph syncon. parent is the number of a Knowledge Graph syncon which, conceptually, is the parent of the concept expressed by the token. For example, if the token has been recognized as a person's name, its parent is the concept of person . The parent syncon data is located in the knowledge array.","title":"tokens"},{"location":"reference/output/linguistic-analysis/#phrases","text":"The phrases array is created and populated by the text subdivision process. It contains an item for every phrase detected. For example, the phrase: Michael Jordan was one of the best basketball players of all time . corresponds to an array item like this: { \"tokens\" : [ 7 , 8 , 9 ], \"type\" : \"PP\" , \"start\" : 54 , \"end\" : 65 } The tokens array contains the zero-based indexes of the constituent tokens. For example, token 7 is the 8th token. type specifies the phrase type . start and end are the positions of the phrase in the analyzed text, which is the value of the content property of the outer data object.","title":"phrases"},{"location":"reference/output/linguistic-analysis/#sentences","text":"The sentences array is created and populated by the text subdivision process. It contains an item for every sentence detected. For example, this sentence: Michael Jordan was one of the best basketball players of all time. corresponds to an array item like this: { \"phrases\" : [ 0 , 1 , 2 , 3 , 4 , 5 ], \"start\" : 0 , \"end\" : 66 } The phrases array contains the zero-based indexes of the constituent phrases. start and end are the positions of the sentence in the analyzed text, which is the value of the content property of the outer data object.","title":"sentences"},{"location":"reference/output/linguistic-analysis/#paragraphs","text":"The paragraphs array is created and populated by the text subdivision process. It contains an item for every paragraph detected. For example this text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. Michael Jordan was also a baseball player and an actor. contains two paragraphs and the corresponding array is something like: \"paragraphs\" : [ { \"sentences\" : [ 0 , 1 ], \"start\" : 0 , \"end\" : 176 }, { \"sentences\" : [ 2 ], \"start\" : 177 , \"end\" : 232 } ] The sentences array in each item contains the zero-based indexes of the constituent sentences. start and end are the positions of the paragraph in the analyzed text, which is the value of the content property of the outer data object.","title":"paragraphs"},{"location":"reference/output/linguistic-analysis/#knowledge","text":"The knowledge array contains Knowledge Graph data for the items of the tokens array. Its contents are described in the article about the output of full analysis .","title":"knowledge"},{"location":"reference/output/relation-extraction/","text":"Relation extraction output The relation extraction resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"paragraphs\": [], \"sentences\": [], \"phrases\": [], \"tokens\": [], \"knowledge\": [], \"relations\": [] } } For the description of the contents , language and version properties, see the API resources output overview . The paragraphs , sentences , phrases and tokens arrays are produced by the text subdivision process . These sections are described in the article about the output of the deep linguistic analysis . The knowledge array contains Knowledge Graph data about the relations elements, as a result of the semantic analysis process. Its contents are described in the article about the output of full analysis . relations Each item of the relations array represents a verb plus the text elements that are in a semantic relation with it. These elements may specify arguments, adjuncts or subordinate clauses. For example, given this input text: John sent a letter to Mary. the relations array can contain an item like this: { \"verb\" : { \"text\" : \"sent\" , \"lemma\" : \"send\" , \"syncon\" : 68296 , \"phrase\" : 1 , \"type\" : \"\" , \"relevance\" : 15 }, \"related\" : [ { \"relation\" : \"sbj_who\" , \"text\" : \"John\" , \"lemma\" : \"John\" , \"syncon\" : -1 , \"type\" : \"NPH\" , \"phrase\" : 0 , \"relevance\" : 15 }, { \"relation\" : \"obj_what\" , \"text\" : \"a letter\" , \"lemma\" : \"letter\" , \"syncon\" : 29131 , \"type\" : \"wrk\" , \"phrase\" : 2 , \"relevance\" : 10 }, { \"relation\" : \"to_who\" , \"text\" : \"to Mary\" , \"lemma\" : \"Mary\" , \"syncon\" : -1 , \"type\" : \"NPH\" , \"phrase\" : 3 , \"relevance\" : 10 } ] } Common properties The verb object and the items of the related array share some properties. text if the portion of text corresponding to the element. phrase is the index of the phrase containing the element. The value must be interpreted as a pointer to an item of the phrases array, where the positions of the first and the last character of the phrase can be found. This information can be used for text highlighting. From the phrase it is possible to go back to the sentence it belongs to\u2014using the sentences array\u2014and from the sentence to the paragraph\u2014using the paragraphs array\u2014,or, going in the opposite direction, to find the tokens contained in the phrase \u2014using the tokens array. Subordinate clauses\u2014related items having the relation property set to sub \u2014do not have a one-to-one correspondence with a phrase. In that case, phrase has the conventional value -1. The syncon and lemma properties are the outcome of semantic analysis and lemmatization respectively. These are exactly the same processes carried out during deep linguistic analysis . Value -1 for syncon means the concept doesn't have a correspondent in the expert.ai Knowledge Graph . This can happen with: entities having a proper noun that are recognized through heuristics (e.g. John Smith ) parts-of-speech that ar not mapped in the Knowledge Graph like pronouns (e.g., them ) subordinate clauses like quotes (e.g., John said: \" I will do it! \" ) In cases 1 and 2 lemma is an empty string. relevance is an indicator of the importance of the element in text. Its values ranges from 1 to 15. When element importance cannot be determined, relevance has the conventional value -1. verb The verb object is always present and it represents the verb. type is the verb type. When set, it can be one of the following: Verb type Description CPL to be used as a connection as in John is a smart guy MOV Verb of movement like to go SAY Verb of communication like to say related The items of the related array represent text elements that are related to the verb. relation is the type of relation and can be one of the following: Possible values of relation sbj_who sbj_what obj_who obj_what is_who is_what to_who to_what using_what preposition* + _what preposition* + _who sub ** when where to_where from_where in_where which_way how of_age limited_to * Prepositions are expressed in the language of the text intelligence engine. For example, a possible value in the case of German language could be auf_what . Multi-word names of prepositional expressions like according to , in front of , ecc., are written in compact form without spaces between words ( accordingto , infrontof ). ** The sub relation type is used for subordinate clauses. type identifies the kind of element. Possible values can be uppercase or lowercase. Uppercase corresponds to named entities, lowercase to generic entities. Relations can be recursive: a related item can be related to another item and so on. In this case an item of the related array can contain a related array. For example, given this input text: Mireille placed the plant pot on the landing at the top of the stairs. relations can be like this: \"relations\" : [ { \"related\" : [ { \"lemma\" : \"Mireille\" , \"phrase\" : 0 , \"relation\" : \"sbj_who\" , \"relevance\" : 14 , \"syncon\" : -1 , \"text\" : \"Mireille\" , \"type\" : \"NPH\" }, { \"lemma\" : \"pot\" , \"phrase\" : 2 , \"relation\" : \"obj_what\" , \"relevance\" : 15 , \"syncon\" : 18506 , \"text\" : \"the plant pot\" , \"type\" : \"prd\" }, { \"lemma\" : \"landing\" , \"phrase\" : 3 , \"relation\" : \"on_what\" , \"relevance\" : 5 , \"syncon\" : 16859 , \"text\" : \"on the landing\" , \"type\" : \"bld\" }, { \"lemma\" : \"top\" , \"phrase\" : 4 , \"related\" : [ { \"lemma\" : \"stairs\" , \"phrase\" : 5 , \"relation\" : \"of_what\" , \"relevance\" : 1 , \"syncon\" : 20016 , \"text\" : \"of the stairs\" , \"type\" : \"bld\" } ], \"relation\" : \"at_what\" , \"relevance\" : -1 , \"syncon\" : 37732 , \"text\" : \"at the top\" , \"type\" : \"\" } ], \"verb\" : { \"lemma\" : \"place\" , \"phrase\" : 1 , \"relevance\" : 15 , \"syncon\" : 68498 , \"text\" : \"placed\" , \"type\" : \"\" } } ] knowledge The knowledge array contains Knowledge Graph data for the items of the relations array. Its contents are described in the article about the output of full analysis .","title":"Relation extraction"},{"location":"reference/output/relation-extraction/#relation-extraction-output","text":"The relation extraction resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"paragraphs\": [], \"sentences\": [], \"phrases\": [], \"tokens\": [], \"knowledge\": [], \"relations\": [] } } For the description of the contents , language and version properties, see the API resources output overview . The paragraphs , sentences , phrases and tokens arrays are produced by the text subdivision process . These sections are described in the article about the output of the deep linguistic analysis . The knowledge array contains Knowledge Graph data about the relations elements, as a result of the semantic analysis process. Its contents are described in the article about the output of full analysis .","title":"Relation extraction output"},{"location":"reference/output/relation-extraction/#relations","text":"Each item of the relations array represents a verb plus the text elements that are in a semantic relation with it. These elements may specify arguments, adjuncts or subordinate clauses. For example, given this input text: John sent a letter to Mary. the relations array can contain an item like this: { \"verb\" : { \"text\" : \"sent\" , \"lemma\" : \"send\" , \"syncon\" : 68296 , \"phrase\" : 1 , \"type\" : \"\" , \"relevance\" : 15 }, \"related\" : [ { \"relation\" : \"sbj_who\" , \"text\" : \"John\" , \"lemma\" : \"John\" , \"syncon\" : -1 , \"type\" : \"NPH\" , \"phrase\" : 0 , \"relevance\" : 15 }, { \"relation\" : \"obj_what\" , \"text\" : \"a letter\" , \"lemma\" : \"letter\" , \"syncon\" : 29131 , \"type\" : \"wrk\" , \"phrase\" : 2 , \"relevance\" : 10 }, { \"relation\" : \"to_who\" , \"text\" : \"to Mary\" , \"lemma\" : \"Mary\" , \"syncon\" : -1 , \"type\" : \"NPH\" , \"phrase\" : 3 , \"relevance\" : 10 } ] }","title":"relations"},{"location":"reference/output/relation-extraction/#common-properties","text":"The verb object and the items of the related array share some properties. text if the portion of text corresponding to the element. phrase is the index of the phrase containing the element. The value must be interpreted as a pointer to an item of the phrases array, where the positions of the first and the last character of the phrase can be found. This information can be used for text highlighting. From the phrase it is possible to go back to the sentence it belongs to\u2014using the sentences array\u2014and from the sentence to the paragraph\u2014using the paragraphs array\u2014,or, going in the opposite direction, to find the tokens contained in the phrase \u2014using the tokens array. Subordinate clauses\u2014related items having the relation property set to sub \u2014do not have a one-to-one correspondence with a phrase. In that case, phrase has the conventional value -1. The syncon and lemma properties are the outcome of semantic analysis and lemmatization respectively. These are exactly the same processes carried out during deep linguistic analysis . Value -1 for syncon means the concept doesn't have a correspondent in the expert.ai Knowledge Graph . This can happen with: entities having a proper noun that are recognized through heuristics (e.g. John Smith ) parts-of-speech that ar not mapped in the Knowledge Graph like pronouns (e.g., them ) subordinate clauses like quotes (e.g., John said: \" I will do it! \" ) In cases 1 and 2 lemma is an empty string. relevance is an indicator of the importance of the element in text. Its values ranges from 1 to 15. When element importance cannot be determined, relevance has the conventional value -1.","title":"Common properties"},{"location":"reference/output/relation-extraction/#verb","text":"The verb object is always present and it represents the verb. type is the verb type. When set, it can be one of the following: Verb type Description CPL to be used as a connection as in John is a smart guy MOV Verb of movement like to go SAY Verb of communication like to say","title":"verb"},{"location":"reference/output/relation-extraction/#related","text":"The items of the related array represent text elements that are related to the verb. relation is the type of relation and can be one of the following: Possible values of relation sbj_who sbj_what obj_who obj_what is_who is_what to_who to_what using_what preposition* + _what preposition* + _who sub ** when where to_where from_where in_where which_way how of_age limited_to * Prepositions are expressed in the language of the text intelligence engine. For example, a possible value in the case of German language could be auf_what . Multi-word names of prepositional expressions like according to , in front of , ecc., are written in compact form without spaces between words ( accordingto , infrontof ). ** The sub relation type is used for subordinate clauses. type identifies the kind of element. Possible values can be uppercase or lowercase. Uppercase corresponds to named entities, lowercase to generic entities. Relations can be recursive: a related item can be related to another item and so on. In this case an item of the related array can contain a related array. For example, given this input text: Mireille placed the plant pot on the landing at the top of the stairs. relations can be like this: \"relations\" : [ { \"related\" : [ { \"lemma\" : \"Mireille\" , \"phrase\" : 0 , \"relation\" : \"sbj_who\" , \"relevance\" : 14 , \"syncon\" : -1 , \"text\" : \"Mireille\" , \"type\" : \"NPH\" }, { \"lemma\" : \"pot\" , \"phrase\" : 2 , \"relation\" : \"obj_what\" , \"relevance\" : 15 , \"syncon\" : 18506 , \"text\" : \"the plant pot\" , \"type\" : \"prd\" }, { \"lemma\" : \"landing\" , \"phrase\" : 3 , \"relation\" : \"on_what\" , \"relevance\" : 5 , \"syncon\" : 16859 , \"text\" : \"on the landing\" , \"type\" : \"bld\" }, { \"lemma\" : \"top\" , \"phrase\" : 4 , \"related\" : [ { \"lemma\" : \"stairs\" , \"phrase\" : 5 , \"relation\" : \"of_what\" , \"relevance\" : 1 , \"syncon\" : 20016 , \"text\" : \"of the stairs\" , \"type\" : \"bld\" } ], \"relation\" : \"at_what\" , \"relevance\" : -1 , \"syncon\" : 37732 , \"text\" : \"at the top\" , \"type\" : \"\" } ], \"verb\" : { \"lemma\" : \"place\" , \"phrase\" : 1 , \"relevance\" : 15 , \"syncon\" : 68498 , \"text\" : \"placed\" , \"type\" : \"\" } } ]","title":"related"},{"location":"reference/output/relation-extraction/#knowledge","text":"The knowledge array contains Knowledge Graph data for the items of the relations array. Its contents are described in the article about the output of full analysis .","title":"knowledge"},{"location":"reference/output/sentiment-analysis/","text":"Sentiment analysis output The sentiment analysis resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"sentiment\": [] } } For the description of the contents , language and version properties, see the API resources output overview . The knowledge array contains Knowledge Graph data about items of the sentiment array, as a result of the semantic analysis process. Its contents are described in the article about the output of full analysis . sentiment The sentiment object contains three scores indicative of the tone of the whole text: positivity : the amount of positivity negativity : the amount of negativity overall : the overall sentiment score, which is a combination of the scores above All sentiment scores are expressed in a -100 (extremely negative) to 100 (extremely positive) range. The sentiment object contains an items array whose elements, in turn, can contain nested items arrays. These items represent the clusters of text elements that give a positive or negative contribution to sentiment. For example, given this input text: The road was bad. items clusters can be like this: \"items\" : [ { \"lemma\" : \"road\" , \"sentiment\" : -7 , \"syncon\" : 19001 , \"items\" : [ { \"lemma\" : \"bad\" , \"sentiment\" : -7 , \"syncon\" : 81195 } ] } ] sentiment is the sentiment score of the cluster or leaf-item. The sentiment score of a cluster is a function of the child items' scores and the the possible modifiers, which are not returned as separate item, but are nevertheless taken into account. Take, for example, a slight change introduced in the sample text: The road was really bad. the really modifier makes the score get worse: \"items\" : [ { \"lemma\" : \"road\" , \"sentiment\" : -8.8 , \"syncon\" : 19001 , \"items\" : [ { \"lemma\" : \"bad\" , \"sentiment\" : -8.8 , \"syncon\" : 81195 } ] } ] On the other hand, a not before bad can invert the sentiment polarity from negative to positive. The sentiment value can be zero. The syncon and lemma properties are the outcome of semantic analysis and lemmatization respectively. These are the same processes carried out during deep linguistic analysis , but the value of lemma can have some peculiarities. An item having nested items can be an \"unnamed cluster\": in that case the lemma property is an empty string. If the intrinsic item polarity\u2014positive or negative\u2014is opposite of that of the paragraph it belongs to, this marker: [*] is added as a suffix to the the lemma. For example, given this input text: The road was not bad. The lemma for bad is marked with the \"opposite polarity\" sign because it is negated by not : \"items\" : [ { \"items\" : [ { \"lemma\" : \"bad[*]\" , \"sentiment\" : 7 , \"syncon\" : 87597 } ], \"lemma\" : \"road\" , \"sentiment\" : 7 , \"syncon\" : 19001 } ] Another possibility is that a lemma \"attracts\" other words in the same phrase. For example, given the input text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. a value of lemma could be: stand-out;skill In this case the merged terms are separated by a semi-colon ( ; ). Value -1 for syncon means the concept doesn't have a correspondent in the expert.ai Knowledge Graph . knowledge The knowledge array contains Knowledge Graph data for the elements of the items array. Its contents are described in the article about the output of full analysis .","title":"Sentiment analysis"},{"location":"reference/output/sentiment-analysis/#sentiment-analysis-output","text":"The sentiment analysis resource returns a JSON object with this format: { \"success\": Boolean success flag , \"data\": { \"content\": analyzed text , \"language\": language code , \"version\": technology version info , \"knowledge\": [], \"sentiment\": [] } } For the description of the contents , language and version properties, see the API resources output overview . The knowledge array contains Knowledge Graph data about items of the sentiment array, as a result of the semantic analysis process. Its contents are described in the article about the output of full analysis .","title":"Sentiment analysis output"},{"location":"reference/output/sentiment-analysis/#sentiment","text":"The sentiment object contains three scores indicative of the tone of the whole text: positivity : the amount of positivity negativity : the amount of negativity overall : the overall sentiment score, which is a combination of the scores above All sentiment scores are expressed in a -100 (extremely negative) to 100 (extremely positive) range. The sentiment object contains an items array whose elements, in turn, can contain nested items arrays. These items represent the clusters of text elements that give a positive or negative contribution to sentiment. For example, given this input text: The road was bad. items clusters can be like this: \"items\" : [ { \"lemma\" : \"road\" , \"sentiment\" : -7 , \"syncon\" : 19001 , \"items\" : [ { \"lemma\" : \"bad\" , \"sentiment\" : -7 , \"syncon\" : 81195 } ] } ] sentiment is the sentiment score of the cluster or leaf-item. The sentiment score of a cluster is a function of the child items' scores and the the possible modifiers, which are not returned as separate item, but are nevertheless taken into account. Take, for example, a slight change introduced in the sample text: The road was really bad. the really modifier makes the score get worse: \"items\" : [ { \"lemma\" : \"road\" , \"sentiment\" : -8.8 , \"syncon\" : 19001 , \"items\" : [ { \"lemma\" : \"bad\" , \"sentiment\" : -8.8 , \"syncon\" : 81195 } ] } ] On the other hand, a not before bad can invert the sentiment polarity from negative to positive. The sentiment value can be zero. The syncon and lemma properties are the outcome of semantic analysis and lemmatization respectively. These are the same processes carried out during deep linguistic analysis , but the value of lemma can have some peculiarities. An item having nested items can be an \"unnamed cluster\": in that case the lemma property is an empty string. If the intrinsic item polarity\u2014positive or negative\u2014is opposite of that of the paragraph it belongs to, this marker: [*] is added as a suffix to the the lemma. For example, given this input text: The road was not bad. The lemma for bad is marked with the \"opposite polarity\" sign because it is negated by not : \"items\" : [ { \"items\" : [ { \"lemma\" : \"bad[*]\" , \"sentiment\" : 7 , \"syncon\" : 87597 } ], \"lemma\" : \"road\" , \"sentiment\" : 7 , \"syncon\" : 19001 } ] Another possibility is that a lemma \"attracts\" other words in the same phrase. For example, given the input text: Michael Jordan was one of the best basketball players of all time. Scoring was Jordan's stand-out skill, but he still holds a defensive NBA record, with eight steals in a half. a value of lemma could be: stand-out;skill In this case the merged terms are separated by a semi-colon ( ; ). Value -1 for syncon means the concept doesn't have a correspondent in the expert.ai Knowledge Graph .","title":"sentiment"},{"location":"reference/output/sentiment-analysis/#knowledge","text":"The knowledge array contains Knowledge Graph data for the elements of the items array. Its contents are described in the article about the output of full analysis .","title":"knowledge"},{"location":"reference/output/taxonomies-templates/","text":"Self-documentation resources output Categories' tree The output of the self-documentation resource returning the categories' tree is a JSON object like this: { \"taxonomy\" : [ { \"namespace\" : \"cat-geo_en_1.0\" , \"categories\" : [ { \"id\" : \"GEO_TAX\" , \"label\" : \"Geo Taxonomy\" , \"categories\" : [ { \"id\" : \"001.\" , \"label\" : \"Afghanistan\" }, { \"id\" : \"002.\" , \"label\" : \"Albania\" }, ... { \"id\" : \"193.\" , \"label\" : \"Zambia\" }, { \"id\" : \"194.\" , \"label\" : \"Zimbabwe\" } ] } ] } ] } taxonomy is the root element and it is an array of categories' trees. namespace is the name of the software module inside the text intelligence engine in which the categories' tree is defined, while categories is an array of possibly nested categories. Each category is an object with these properties: id : category identifier label : category label categories : sub-categories There can be several categories with the same value for id in the categories' tree, but there cannot be two or more categories with the same id under the same parent category. Templates The output of the self-documentation resource returning the information extraction templates is a JSON object like this: { \"templates\" : [ { \"name\" : \"PERSONAL_DATA\" , \"fields\" : [ { \"name\" : \"FirstName\" , \"type\" : \"\" }, { \"name\" : \"LastName\" , \"type\" : \"\" } ] }, { \"name\" : \"COMPANY_DATA\" , \"fields\" : [ { \"name\" : \"Name\" , \"type\" : \"C\" }, { \"name\" : \"Country\" , \"type\" : \"\" } ] } ] } templates is the root element and it is an array of template. Each template object has name and fields . name is the name of a specific template, while fields is an array of the fields in the template. Each field is an object with these properties: name : field name type : C is the field was defined as the main field of the template, the empty string otherwise","title":"Self-documentation resources"},{"location":"reference/output/taxonomies-templates/#self-documentation-resources-output","text":"","title":"Self-documentation resources output"},{"location":"reference/output/taxonomies-templates/#categories-tree","text":"The output of the self-documentation resource returning the categories' tree is a JSON object like this: { \"taxonomy\" : [ { \"namespace\" : \"cat-geo_en_1.0\" , \"categories\" : [ { \"id\" : \"GEO_TAX\" , \"label\" : \"Geo Taxonomy\" , \"categories\" : [ { \"id\" : \"001.\" , \"label\" : \"Afghanistan\" }, { \"id\" : \"002.\" , \"label\" : \"Albania\" }, ... { \"id\" : \"193.\" , \"label\" : \"Zambia\" }, { \"id\" : \"194.\" , \"label\" : \"Zimbabwe\" } ] } ] } ] } taxonomy is the root element and it is an array of categories' trees. namespace is the name of the software module inside the text intelligence engine in which the categories' tree is defined, while categories is an array of possibly nested categories. Each category is an object with these properties: id : category identifier label : category label categories : sub-categories There can be several categories with the same value for id in the categories' tree, but there cannot be two or more categories with the same id under the same parent category.","title":"Categories' tree"},{"location":"reference/output/taxonomies-templates/#templates","text":"The output of the self-documentation resource returning the information extraction templates is a JSON object like this: { \"templates\" : [ { \"name\" : \"PERSONAL_DATA\" , \"fields\" : [ { \"name\" : \"FirstName\" , \"type\" : \"\" }, { \"name\" : \"LastName\" , \"type\" : \"\" } ] }, { \"name\" : \"COMPANY_DATA\" , \"fields\" : [ { \"name\" : \"Name\" , \"type\" : \"C\" }, { \"name\" : \"Country\" , \"type\" : \"\" } ] } ] } templates is the root element and it is an array of template. Each template object has name and fields . name is the name of a specific template, while fields is an array of the fields in the template. Each field is an object with these properties: name : field name type : C is the field was defined as the main field of the template, the empty string otherwise","title":"Templates"},{"location":"reference/phrase-types/","text":"Phrase types These are the types of phrases recognized during the subdivision process of deep linguistic analysis: Code Description AP Adjective Phrase CP Conjunction Phrase CR Blank lines DP Adverb Phrase NA Not Applicable (usually indicates punctuation) NP Noun Phrase PN Nominal Predicate PP Preposition Phrase RP Relative Phrase VP Verb Phrase","title":"Phrase types"},{"location":"reference/phrase-types/#phrase-types","text":"These are the types of phrases recognized during the subdivision process of deep linguistic analysis: Code Description AP Adjective Phrase CP Conjunction Phrase CR Blank lines DP Adverb Phrase NA Not Applicable (usually indicates punctuation) NP Noun Phrase PN Nominal Predicate PP Preposition Phrase RP Relative Phrase VP Verb Phrase","title":"Phrase types"},{"location":"reference/positions/","text":"Positions All the analysis resources, whether document analysis , document classification or information extraction , return the positions of the blocks of text corresponding to each information discovered by the analysis. For example: The deep linguistic analysis resource returns the positions of all the subdivisions of the tex: paragraphs, sentences, phrases, tokens and atoms. The keyphrase extraction resource returns the positions of main sentences, main phrases, main concepts and main lemmas. The classification resources return the positions of the parts of the text that triggered categorization rules. All these positions refer to blocks of the analyzed text, that is the content property of the data object. The starting position is returned in the start property and the ending position in the end property. The value of the start property is the zero-based index of the first character of the block . For example, if a text begins with: Michael Jordan was one of the best basketball players of all time. the start position of phrase of all time is 54: Michael Jordan was one of the best basketball players of all time . \u2191 012345678901234567890123456789012345678901234567890123 4 5678901234567890 0 1 2 3 4 5 6 7 The value of the end position is the zero-based index of the first character after the text block . In the example case above, the end position of the phrase is 65: Michael Jordan was one of the best basketball players of all time . \u2191 01234567890123456789012345678901234567890123456789012345678901234 5 67890 0 1 2 3 4 5 6 7","title":"Positions"},{"location":"reference/positions/#positions","text":"All the analysis resources, whether document analysis , document classification or information extraction , return the positions of the blocks of text corresponding to each information discovered by the analysis. For example: The deep linguistic analysis resource returns the positions of all the subdivisions of the tex: paragraphs, sentences, phrases, tokens and atoms. The keyphrase extraction resource returns the positions of main sentences, main phrases, main concepts and main lemmas. The classification resources return the positions of the parts of the text that triggered categorization rules. All these positions refer to blocks of the analyzed text, that is the content property of the data object. The starting position is returned in the start property and the ending position in the end property. The value of the start property is the zero-based index of the first character of the block . For example, if a text begins with: Michael Jordan was one of the best basketball players of all time. the start position of phrase of all time is 54: Michael Jordan was one of the best basketball players of all time . \u2191 012345678901234567890123456789012345678901234567890123 4 5678901234567890 0 1 2 3 4 5 6 7 The value of the end position is the zero-based index of the first character after the text block . In the example case above, the end position of the phrase is 65: Michael Jordan was one of the best basketball players of all time . \u2191 01234567890123456789012345678901234567890123456789012345678901234 5 67890 0 1 2 3 4 5 6 7","title":"Positions"},{"location":"reference/requests/","text":"Requests All essex API requests must: Use the POST method. Contain an UTF-8 encoded JSON object as their payload. Have this header: application/json; charset=utf-8 Be sent to one of the API endpoints . If analysis is required, whether document analysis , document classification or information extraction , the JSON object must contain the text to parse. In all cases the object contains parameters that specify the request. For example, the JSON object to send in order to request document classification is like this: { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"categories\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Execution mode affects the format of the request. In fact, in server mode, in addition to the text of the document, options and features, it is also necessary to specify the name of the resource that must carry out the analysis. The next articles in this section detail the structure of JSON objects to use to request API resources.","title":"Overview"},{"location":"reference/requests/#requests","text":"All essex API requests must: Use the POST method. Contain an UTF-8 encoded JSON object as their payload. Have this header: application/json; charset=utf-8 Be sent to one of the API endpoints . If analysis is required, whether document analysis , document classification or information extraction , the JSON object must contain the text to parse. In all cases the object contains parameters that specify the request. For example, the JSON object to send in order to request document classification is like this: { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"categories\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Execution mode affects the format of the request. In fact, in server mode, in addition to the text of the document, options and features, it is also necessary to specify the name of the resource that must carry out the analysis. The next articles in this section detail the structure of JSON objects to use to request API resources.","title":"Requests"},{"location":"reference/requests/classification/","text":"Document classification requests The JSON object that constitutes the payload of requests for document classification varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"categories\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"categories\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Document classification"},{"location":"reference/requests/classification/#document-classification-requests","text":"The JSON object that constitutes the payload of requests for document classification varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"categories\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"categories\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Document classification requests"},{"location":"reference/requests/entity-recognition/","text":"Named entity recognition requests The JSON object that constitutes the payload of requests for named entity recognition varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"entities\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"extractions\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Named entity recognition"},{"location":"reference/requests/entity-recognition/#named-entity-recognition-requests","text":"The JSON object that constitutes the payload of requests for named entity recognition varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"entities\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"extractions\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Named entity recognition requests"},{"location":"reference/requests/extraction/","text":"Information extraction requests The JSON object that constitutes the payload of requests for information extraction varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"extractions\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"extractions\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Information extraction"},{"location":"reference/requests/extraction/#information-extraction-requests","text":"The JSON object that constitutes the payload of requests for information extraction varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"extractions\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"extractions\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Information extraction requests"},{"location":"reference/requests/full-analysis/","text":"Full document analysis requests The JSON object that constitutes the payload of requests for full document analysis varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" , \"relevants\" , \"entities\" , \"sentiment\" , \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" , \"relevants\" , \"entities\" , \"sentiment\" , \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Full analysis"},{"location":"reference/requests/full-analysis/#full-document-analysis-requests","text":"The JSON object that constitutes the payload of requests for full document analysis varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" , \"relevants\" , \"entities\" , \"sentiment\" , \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" , \"relevants\" , \"entities\" , \"sentiment\" , \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Full document analysis requests"},{"location":"reference/requests/keyphrase-extraction/","text":"Keyphrase extraction requests The JSON object that constitutes the payload of requests for keyphrase extraction varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relevants\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relevants\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Keyphrase extraction"},{"location":"reference/requests/keyphrase-extraction/#keyphrase-extraction-requests","text":"The JSON object that constitutes the payload of requests for keyphrase extraction varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relevants\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relevants\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Keyphrase extraction requests"},{"location":"reference/requests/linguistic-analysis/","text":"Deep linguistic analysis requests The JSON object that constitutes the payload of requests for deep linguistic analysis varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Deep linguistic analysis"},{"location":"reference/requests/linguistic-analysis/#deep-linguistic-analysis-requests","text":"The JSON object that constitutes the payload of requests for deep linguistic analysis varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"disambiguation\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Deep linguistic analysis requests"},{"location":"reference/requests/relation-extraction/","text":"Relation extraction requests The JSON object that constitutes the payload of requests for relation extraction varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Relation extraction"},{"location":"reference/requests/relation-extraction/#relation-extraction-requests","text":"The JSON object that constitutes the payload of requests for relation extraction varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"relations\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Relation extraction requests"},{"location":"reference/requests/sentiment-analysis/","text":"Sentiment analysis requests The JSON object that constitutes the payload of requests for sentiment analysis varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"sentiment\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"sentiment\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Sentiment analysis"},{"location":"reference/requests/sentiment-analysis/#sentiment-analysis-requests","text":"The JSON object that constitutes the payload of requests for sentiment analysis varies based on essex execution mode and must be like this: Single resource mode { \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"sentiment\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } } Server mode { \"resource\" : \"Resource name here\" , \"document\" : { \"text\" : \"Your text here.\" }, \"options\" : { \"analysis\" : [ \"sentiment\" ], \"features\" : [ \"knowledge\" , \"dependency\" , \"syncpos\" ] } }","title":"Sentiment analysis requests"},{"location":"reference/requests/taxonomies-templates/","text":"Self-documentation resources requests Categories' tree The JSON object that constitutes the payload of the request for the categories' tree self-documentation resource varies based on essex execution mode and must be like this: Single resource mode { \"info\" : \"taxonomy\" } Server mode { \"resource\" : \"Resource name here\" , \"info\" : \"taxonomy\" } Templates The JSON object that constitutes the payload of the request for information extraction templates self-documentation resource varies based on essex execution mode and must be like this: Single resource mode { \"info\" : \"templates\" } Server mode { \"resource\" : \"Resource name here\" , \"info\" : \"templates\" }","title":"Self-documentation resources"},{"location":"reference/requests/taxonomies-templates/#self-documentation-resources-requests","text":"","title":"Self-documentation resources requests"},{"location":"reference/requests/taxonomies-templates/#categories-tree","text":"The JSON object that constitutes the payload of the request for the categories' tree self-documentation resource varies based on essex execution mode and must be like this: Single resource mode { \"info\" : \"taxonomy\" } Server mode { \"resource\" : \"Resource name here\" , \"info\" : \"taxonomy\" }","title":"Categories' tree"},{"location":"reference/requests/taxonomies-templates/#templates","text":"The JSON object that constitutes the payload of the request for information extraction templates self-documentation resource varies based on essex execution mode and must be like this: Single resource mode { \"info\" : \"templates\" } Server mode { \"resource\" : \"Resource name here\" , \"info\" : \"templates\" }","title":"Templates"},{"location":"reference/topics/","text":"Standard topics Here are the topics that keyphrase extraction can detect. The first column shows the identification number of the topic, which is the same for all languages. The other columns show the topic labels, which vary by language. ID English Spanish French German Italian 0 clothing vestuario v\u00eatements Kleidung abbigliamento 1 homeopathy homeopat\u00eda hom\u00e9opathie Hom\u00f6opathie omeopatia 2 clothing accessories accesorios accessoire Kleidungszubeh\u00f6r accessori 3 acoustics ac\u00fastica acoustique Akustik acustica 4 aviation aeron\u00e1utica a\u00e9ronautique Aeronautik aeronautica 5 air force aeron\u00e1utica militar a\u00e9ronautique militaire Luftwaffe aeronautica militare 6 aeronautic technology aerotecnia a\u00e9rotechnique Luftzeugtechnik aerotecnica 7 agriculture agricultura agriculture Landwirtschaft agricoltura 8 food alimentos nourriture Lebensmittel alimenti 9 animal husbandry crianza y ganader\u00eda \u00e9levage Zucht allevamento 10 mountaineering alpinismo alpinisme Bergsteigen alpinismo 11 anatomy anatom\u00eda anatomie Anatomie anatomia 12 antique trade comercio de antig\u00fcedades antiquit\u00e9 Antiquit\u00e4ten antiquariato 13 anthropology antropolog\u00eda anthropologie Anthropologie antropologia 14 free diving apnea apn\u00e9e Atemstillstand apnea 15 heraldry her\u00e1ldica h\u00e9raldique Heraldik araldica 16 archaeology arqueolog\u00eda arch\u00e9ologie Arch\u00e4ologie archeologia 17 architecture arquitectura architecture Architektur architettura 18 archival studies archiv\u00edstica archivage Archivierung archivistica 19 archery arco arc Bogenschie\u00dfen arco 20 arithmetic aritm\u00e9tica arithm\u00e9tique Arithmetik aritmetica 21 weapons armas armes Bewaffnung armi 22 interior design decoraci\u00f3n ameublement Innenausstattung arredamento 23 art arte art Kunst arte 24 martial arts artes marciales arts martiaux Kampfsport arti marziali 25 crafts artesan\u00eda artisanat Handwerk artigianato 26 artistic crafts artesan\u00eda art\u00edstica artisanat d'art Kunsthandwerk artigianato artistico 27 visual arts artes gr\u00e1ficas graphique graphische Kunst arti grafiche 28 artillery artiller\u00eda artillerie Artillerie artiglieria 29 insurance industry seguros assurance Versicherung assicurazioni 30 auction subastas vente Auktion aste 31 astrophysics astrof\u00edsica astrophysique Astrophysik astrofisica 32 astrology astrolog\u00eda astrologie Astrologie astrologia 33 astronautics astron\u00e1utica astronautique Raumfahrt astronautica 34 astronomy astronom\u00eda astronomie Astronomie astronomia 35 culture t\u00e9rminos culturales termes culturels kulturelle Begriffe termini culturali 36 athletics atletismo athl\u00e9tisme Leichtathletik atletica leggera 37 wrestling and weightlifting halterofilia y lucha halt\u00e9rophilie Schwerathletik atletica pesante 38 automation automatizaci\u00f3n automation Automatisierung automazione 39 motor vehicles veh\u00edculos de motor v\u00e9hicule automobile Kraftfahrzeug autoveicoli 40 motor racing automovilismo automobilisme Motorsport automobilismo 41 air travel aviaci\u00f3n aviation Luftfahrt aviazione 42 ballistics bal\u00edstica balistique Ballistik balistica 43 ballet ballet-baile ballet Ballett balletto-danza 44 banking banco banque Bank banca 45 baseball b\u00e9isbol base-ball Baseball baseball 46 The Bible Biblia Bible Bibel Bibbia 47 libraries bibliotecas biblioth\u00e8que Bibliotheken biblioteche 48 billiard sports billar billard Billard biliardo 49 biochemistry bioqu\u00edmica biochimie Biochemie biochimica 50 biophysics biof\u00edsica biophysique Biophysik biofisica 51 biology biolog\u00eda biologie Biologie biologia 52 biotechnology biotecnolog\u00eda biotechnologie Biotechnologie biotecnologie 53 bobsledding bobsleigh bob Bob bob 54 stock exchange bolsa Bourse B\u00f6rse borsa 55 botany bot\u00e1nica botanique Botanik botanica 56 bowling bolos bowling Bowling bowling 57 boxing boxeo boxe Boxen boxe 58 do it yourself bricolaje bricolage do it yourself bricolage 59 bridge (card game) bridge bridge Bridge bridge 60 Buddhism budismo bouddhisme Buddhismus buddismo 61 hunting caza chasse Jagd caccia 62 CAD (computer aided design) cad cad CAD (rechnerunterst\u00fctzte Konstruktion) cad 63 five-a-side football f\u00fatbol sala football \u00e0 cinq Futsal calcetto 64 soccer (US) f\u00fatbol football Fu\u00dfball calcio 65 footwear calzados chaussure Schuhwerk calzature 66 rowing pirag\u00fcismo aviron Rudern canottaggio 67 singing canto chant Gesang canto 68 coal mining carb\u00f3n charbonnage Kohlebergwerk carbone 69 cardiology cardiolog\u00eda cardiologie Kardiologie cardiologia 70 cartography cartograf\u00eda cartographie Kartographie cartografia 71 pottery cer\u00e1mica c\u00e9ramique T\u00f6pferei ceramica 72 chemistry qu\u00edmica chimie Chemie chimica 73 inorganic chemistry qu\u00edmica inorg\u00e1nica chimie inorganique anorganische Chemie chimica inorganica 74 organic chemistry qu\u00edmica org\u00e1nica chimie organique organische Chemie chimica organica 75 surgery cirug\u00eda chirurgie Chirurgie chirurgia 76 cycling ciclismo cyclisme Radfahren ciclismo 77 film industry cine cin\u00e9ma Kino cinema 78 circus circo cirque Zirkus circo 79 track cycling ciclismo en pista cyclisme sur piste Bahnrennen ciclismo su pista 80 cytology citolog\u00eda cytologie Zytologie citologia 81 collecting coleccionismo collection Sammeln collezionismo 82 trade comercio commerce Handel commercio 83 electronic components piezas electr\u00f3nicas composants \u00e9lectroniques elektronischen Komponenten componenti elettronici 84 music composition composici\u00f3n composition Komposition composizione 85 computer art infoarte computer art Computerkunst computer art 86 computer graphics infograf\u00eda infographie Grafik computer grafica 87 media and communication comunicaci\u00f3n communication Massenkommunikation comunicazione 88 leather processing curtidur\u00eda tannerie Gerberei conceria 89 beauty products cosm\u00e9tica cosm\u00e9tologie Kosmetika cosmesi 90 cosmography cosmograf\u00eda cosmographie Kosmographie cosmografia 91 cricket cr\u00edquet cricket Kricket cricket 92 crime criminalidad criminalit\u00e9 Kriminalit\u00e4t criminalit\u00e0 93 Christianity cristianismo Christianisme Christentum cristianesimo 94 news cr\u00f3nica chronique Nachrichten cronaca 95 database base de datos base de donn\u00e9es Datenbank database 96 decoupage decoupage d\u00e9coupage Serviettentechnik decoupage 97 dermatology dermatolog\u00eda dermatologie Dermatologie dermatologia 98 teaching methodology did\u00e1ctica didactique Didaktik didattica 99 dietetics diet\u00e9tica di\u00e9t\u00e9tique Di\u00e4tetik dietetica 100 diplomacy diplomacia diplomatie Diplomatie diplomazia 101 law derecho droit Gesetz diritto 102 non-criminal law derecho civil droit civil Zivilrecht diritto civile 103 business and commercial law derecho mercantil droit commercial Handelsrecht diritto commerciale 104 international law derecho internacional droit international V\u00f6lkerrecht diritto internazionale 105 criminal law derecho penal droit p\u00e9nal Strafrecht diritto penale 106 private law derecho privado droit priv\u00e9 Privatrecht diritto privato 107 administrative law derecho p\u00fablico y administrativo droit public et administratif Staats-und Verwaltungsrecht diritto pubblico e amministrativo 108 electronic storage discos disques Festplatten dischi 109 illustration dibujo dessin Zeichnung disegno 110 Judaism hebra\u00edsmo juda\u00efsme Judentum ebraismo 111 ecology ecolog\u00eda \u00e9cologie \u00d6kologie ecologia 112 e-commerce comercio electr\u00f3nico e-commerce E-Commerce e-commerce 113 the economy econom\u00eda \u00e9conomie Wirtschaft economia 114 construction industry construcci\u00f3n construction Bauindustrie edilizia 115 publishing industria editorial \u00e9dition Verlagswesen editoria 116 electricity electricidad \u00e9lectricit\u00e9 Elektrizit\u00e4t elettricit\u00e0 117 electronics electr\u00f3nica \u00e9lectronique Elektronik elettronica 118 electrotechnics electrot\u00e9cnica \u00e9lectrotechnique Elektrotechnik elettrotecnica 119 e-mail e-mail e-mail E-Mail e-mail 120 embryology embriolog\u00eda embryologie Embryologie embriologia 121 energy energ\u00eda \u00e9nergie Energie energia 122 puzzles enigm\u00edstica jeux d'esprit R\u00e4tsel enigmistica 123 enology enolog\u00eda \u0153nologie \u00d6nologie enologia 124 entomology entomolog\u00eda entomologie Insektenkunde entomologia 125 epigraphy epigraf\u00eda \u00e9pigraphie Epigraphie epigrafia 126 equitation equitaci\u00f3n \u00e9quitation Reitsport equitazione 127 ethics \u00e9tica \u00e9thique Ethik etica 128 Islam islam islam Islam islam 129 ethnology etnolog\u00eda ethnologie Ethnologie etnologia 130 TV broadcasting eventos televisivos \u00e9v\u00e9nements t\u00e9l\u00e9vis\u00e9s Rundfunk Veranstaltungen eventi televisivi 131 evolution evoluci\u00f3n \u00e9volution Evolution evoluzione 132 carpentry carpinter\u00eda menuiserie Zimmerei falegnameria 133 pharmaceuticals farmacia pharmacie Pharmazie farmacia 134 pharmacology farmacolog\u00eda pharmacologie Pharmakologie farmacologia 135 trains ferrocarril chemin de fer Eisenbahn ferrovia 136 philately filatelia philat\u00e9lie Briefmarkensammeln filatelia 137 philology filolog\u00eda philologie Philologie filologia 138 philosophy filosof\u00eda philosophie Philosophie filosofia 139 finance finanzas finance Finanz finanza 140 finance (private) finanzas privadas finances priv\u00e9es Privatfinanz finanza privata 141 public financing finanzas p\u00fablicas finances publiques \u00f6ffentliche Finanz finanza pubblica 142 revenue services fisco fisc Einnahmen fisco 143 physics f\u00edsica physique Physik fisica 144 atomic physics f\u00edsica at\u00f3mica physique atomique Atomphysik fisica atomica 145 physiology fisiolog\u00eda physiologie Physiologie fisiologia 146 phytopathology fitopatolog\u00eda phytopathologie Phytopathologie fitopatologia 147 folklore folclore folklore Volkskunde folclore 148 phonetics fon\u00e9tica phon\u00e9tique Phonetik fonetica 149 phonology fonolog\u00eda phonologie Phonologie fonologia 150 American football f\u00fatbol americano football am\u00e9ricain American Football football americano 151 photography fotograf\u00eda photographie Fotografie fotografia 152 artistic photography fotograf\u00eda art\u00edstica photographie artistique k\u00fcnstlerische Fotografie fotografia artistica 153 free climbing escalada libre free climbing Klettern free climbing 154 fruit growing fruticultura arboriculture fruiti\u00e8re Obstbau frutticoltura 155 cartoons and comic books historieta bande dessin\u00e9e Comics fumetto 156 art galleries galer\u00edas galerie Galerie gallerie 157 gastronomy gastronom\u00eda gastronomie Gastronomie gastronomia 158 genealogy genealog\u00eda g\u00e9n\u00e9alogie Genealogie genealogia 159 genetics gen\u00e9tica g\u00e9n\u00e9tique Genetik genetica 160 geophysics geof\u00edsica g\u00e9ophysique Geophysik geofisica 161 geography geograf\u00eda g\u00e9ographie Geographie geografia 162 geology geolog\u00eda g\u00e9ologie Geologie geologia 163 geometry geometr\u00eda g\u00e9om\u00e9trie Geometrie geometria 164 gardening jardiner\u00eda jardinage G\u00e4rtnerei giardinaggio 165 toys juguetes jouets Spielzeuge giocattoli 166 card games juegos de naipes jeux de cartes Kartenspielen giochi con le carte 167 games and toys juego jeu Spiel gioco 168 jewelry joyer\u00eda bijouterie Schmuck gioielleria 169 the press peri\u00f3dicos journaux Zeitungen giornali 170 journalism periodismo journalisme Journalismus giornalismo 171 go-karting kart go-kart Go-Kart go kart 172 golf golf golf Golf golf 173 graffiti grafiti graffiti Graffito graffiti 174 grammar and syntax gram\u00e1tica grammaire Grammatik grammatica 175 computer hardware hardware mat\u00e9riel Hardware hardware 176 hockey hockey hockey Hockey hockey 177 ice hockey hockey sobre hielo hockey sur glace Eishockey hockey su ghiaccio 178 hydraulics hidr\u00e1ulica hydraulique Hydraulik idraulica 179 immunology inmunolog\u00eda immunologie Immunologie immunologia 180 business empresa entreprise Firma impresa 181 engraving grabado gravure Gravierung incisione 182 industry industria industrie Industrie industria 183 aeronautics industry industria aeron\u00e1utica industrie a\u00e9ronautique Luftfahrtindustrie industria aeronautica 184 food industry industria alimentaria industrie alimentaire Lebensmittelindustrie industria alimentare 185 automotive industry industria automov\u00edlistica industrie automobile Autoindustrie industria automobilistica 186 arms industry industria b\u00e9lica industrie de guerre Kriegsindustrie industria bellica 187 footwear industry industria del calzado industrie de la chaussure Schuhindustrie industria calzaturiera 188 ceramic industry industria cer\u00e1mica industrie c\u00e9ramique Keramikindustrie industria ceramica 189 chemical industry industria qu\u00edmica industrie chimique Chemieindustrie industria chimica 190 rail transport industria del ferrocarril industrie de chemin de fer Eisenbahnindustrie industria ferroviaria 191 furniture industry industria mueblera industrie des meubles M\u00f6belindustrie industria mobiliera 192 motorcycle industry industria motociclista industrie de motos Motorrad-Industrie industria motociclistica 193 shipbuilding industria n\u00e1utica industrie naval Schifffahrtsindustrie industria nautica 194 textile industry industria textil industrie textiles Textilindustrie industria tessile 195 glass manufacturing industria del vidrio industrie de verre Glasherstellung industria vetraria 196 industrial design dise\u00f1o industrial dessin industriel Industriedesign industrial design 197 computer science inform\u00e1tica informatique Informatik informatica 198 engineering ingenier\u00eda g\u00e9nie Ingenieurwesen ingegneria 199 aerospace engineering ingenier\u00eda aeroespacial g\u00e9nie a\u00e9rospatial Luft- und Raumfahrttechnik ingegneria aerospaziale 200 Internet internet internet Internet internet 201 intranet intranet intranet Intranet intranet 202 equestrian sports h\u00edpica hippisme Pferderennen ippica 203 institutions instituciones institutions Institute istituzioni 204 education instrucci\u00f3n enseignement Bildung istruzione 205 ichthyology ictiolog\u00eda ichtyologie Fischkunde ittiologia 206 kayaking kayak kayak Kajak kayak 207 needlework trabajos de cosido ouvrage d'aiguilles Nadelarbeit lavori di cucito 208 job market trabajo travail Arbeit lavoro 209 legislation legislaci\u00f3n l\u00e9gislation Gesetzgebung legislazione 210 judo judo judo Judo judo 211 literature literatura litt\u00e9rature Literatur letteratura 212 linguistics ling\u00fc\u00edstica linguistique Linguistik linguistica 213 lithography litograf\u00eda lithographie Lithographie litografia 214 liturgy liturgia liturgie Liturgie liturgia 215 lottery loter\u00eda loterie Lotterie lotterie 216 animal slaughter mataderos abattage Schlachtung macellazione 217 knitting punto tricot Stricken maglia 218 manufacturing manufactura manufacture Herstellung manifattura 219 watercraft and nautical navigation marina marine Flotte marina 220 naval forces marina militar marine militaire Marine marina militare 221 marketing marketing marketing Marketing marketing 222 mathematics matem\u00e1tica math\u00e9matiques Mathematik matematica 223 mechanics mec\u00e1nica m\u00e9canique Mechanik meccanica 224 public administration administraci\u00f3n p\u00fablica administration publique Beh\u00f6rde amministrazione pubblica 225 medicine medicina m\u00e9decine Medizin medicina 226 alternative medicine medicina alternativa m\u00e9decine douce Alternative Medizin medicina alternativa 227 data storage memoria m\u00e9moire Speicher memoria 228 board games juegos de mesa jeux de table Brettspiele giochi da tavolo 229 metallurgy metalurgia m\u00e9tallurgie Metallurgie metallurgia 230 meteorology meteorolog\u00eda m\u00e9t\u00e9orologie Meteorologie meteorologia 231 meter and prosody m\u00e9trica m\u00e9trique Metrik metrica 232 ophthalmology oftalmolog\u00eda ophtalmologie Augenheilkunde oculistica 233 microbiology microbiolog\u00eda microbiologie Mikrobiologie microbiologia 234 armed forces militar militaire Milit\u00e4r militare 235 mineralogy mineralog\u00eda min\u00e9ralogie Mineralogie mineralogia 236 mines minas mines Minen miniere 237 government departments and ministries ministerios Minist\u00e8res Ministerien ministeri 238 rocket science tecnolog\u00eda misil\u00edstica missile Raketen missilistica 239 mythology mitolog\u00eda mythologie Mythologie mitologia 240 furniture muebles meubles M\u00f6blierung mobili 241 fashion moda mode Mode moda 242 computer monitor monitor \u00e9cran Monitor monitor 243 motorcycling motociclismo motocyclisme Motorradfahren motociclismo 244 powertrain design and engineering ingenier\u00eda mec\u00e1nica sports motoris\u00e9s Design und Technik motoristica 245 multimedia multimedia multim\u00e9dia Multimedia multimedia 246 masonry alba\u00f1iler\u00eda ma\u00e7onnerie Mauerwerk muratura 247 museums museos mus\u00e9es Museen musei 248 music m\u00fasica musique Musik musica 249 numismatics numism\u00e1tica numismatique Numismatik numismatica 250 swimming nataci\u00f3n nage Schwimmen nuoto 251 occultism ocultismo occultisme Okkultismus occultismo 252 hydrography hidrograf\u00eda hydrographie Hydrographie idrografia 253 orthodontics odontolog\u00eda odontologie Kieferorthop\u00e4die odontoiatria 254 oncology oncolog\u00eda oncologie Onkologie oncologia 255 opera \u00f3pera op\u00e9ra Oper opera 256 goldsmithing orfebrer\u00eda orf\u00e8vrerie Juwelierskunst oreficeria 257 ornithology ornitolog\u00eda ornithologie Vogelkunde ornitologia 258 watchmaking relojer\u00eda horlogerie Uhrenindustrie orologeria 259 orthopedics ortopedia orthop\u00e9die Orthop\u00e4die ortopedia 260 hospitals hospital h\u00f4pital Krankenhaus ospedale 261 optics \u00f3ptica optique Optik ottica 262 paleography paleograf\u00eda pal\u00e9ographie Pal\u00e4ographie paleografia 263 paleontology paleontolog\u00eda pal\u00e9ontologie Pal\u00e4ontologie paleontologia 264 paleozoology paleozoolog\u00eda pal\u00e9ozoologie Pal\u00e4ozoologie paleozoologia 265 basketball baloncesto basket-ball Basketball pallacanestro 266 handball balonmano handball Handball pallamano 267 water polo polo acu\u00e1tico water-polo Wasserball pallanuoto 268 volleyball voleibol volley-ball Volleyball pallavolo 269 papyrology papirolog\u00eda papyrologie Papyrologie papirologia 270 parapsychology parapsicolog\u00eda parapsychologie Parapsychologie parapsicologia 271 Parliament and legislative bodies parlamento parlement Parlament parlamento 272 skating patinaje patinage Schlittschuhlaufen pattinaggio 273 pedagogy pedagog\u00eda p\u00e9dagogie P\u00e4dagogie pedagogia 274 classical music m\u00fasica cl\u00e1sica musique classique klassische Musik musica classica 275 fishing pesca p\u00eache Angeln pesca 276 sport fishing pesca deportiva p\u00eache sportive Sportfischen pesca sportiva 277 spearfishing pesca submarina p\u00eache sous-marine Unterwasserfischen pesca subacquea 278 petrochemistry petroqu\u00edmica p\u00e9trochimie Petrochemie petrolchimica 279 petrochemicals petr\u00f3leo p\u00e9trole \u00d6l petrolio 280 table tennis ping-pong ping-pong Tischtennis ping-pong 281 painting pintura peinture Malerei pittura 282 glass painting pintura sobre vidrio peinture sur verre Glasmalerei pittura vetraria 283 poetry poes\u00eda po\u00e9sie Poesie poesia 284 poker p\u00f3quer poker Poker poker 285 politics pol\u00edtica politique Politik politica 286 police polic\u00eda police Polizei polizia 287 postal service correo poste Post posta 288 prehistory prehistoria pr\u00e9histoire Vorgeschichte preistoria 289 welfare previsi\u00f3n \u00e9tat providence Wohlfahrt previdenza 290 computer processors procesadores processeurs Prozessoren processori 291 perfumery perfumer\u00eda parfumerie Parf\u00fcmerie profumeria 292 computer programming programaci\u00f3n programmation Programmierung programmazione 293 office productivity software programas para la oficina programme de bureau Business-Programme programmi per ufficio 294 psychoanalysis psicoan\u00e1lisis psychanalyse Psychoanalyse psicanalisi 295 psychiatry psiquiatr\u00eda psychiatrie Psychiatrie psichiatria 296 psychology psicolog\u00eda psychologie Psychologie psicologia 297 advertising publicidad publicit\u00e9 Werbung pubblicit\u00e0 298 radio broadcasting radio radio Radio radio 299 radiology radiolog\u00eda radiologie Radiologie radiologia 300 kitchen tools utensilios de cocina ustensiles de cuisine K\u00fcchenutensilien strumenti da cucina 301 public relations relaciones p\u00fablicas relations publiques Public Relations relazioni pubbliche 302 religion religi\u00f3n religion Verehrung religione 303 information technology redes r\u00e9seaux Netze reti 304 rhetoric ret\u00f3rica rh\u00e9torique Rhetorik retorica 305 lacework bordado broderie Spitze ricamo 306 restaurant industry restauraci\u00f3n restauration Catering ristorazione 307 robotics rob\u00f3tica robotique Robotik robotica 308 rugby rugby rugby Rugby rugby 309 health care sanidad sant\u00e9 Gesundheitsamt sanit\u00e0 310 tailoring sastrer\u00eda haute couture Schneiderei sartoria 311 chess ajedrez \u00e9checs Schach scacchi 312 scenography escenograf\u00eda sc\u00e9nographie Szenografie scenografia 313 graphics card tarjetas gr\u00e1ficas cartes graphiques Grafikkarten schede grafiche 314 fencing esgrima escrime Fechten scherma 315 skiing esqu\u00ed ski Skifahren sci 316 downhill skiing esqu\u00ed alpino ski alpin Abfahrtsski sci alpino 317 cross-country skiing esqu\u00ed de fondo ski de fond Langlauf sci di fondo 318 water skiing esqu\u00ed n\u00e1utico ski nautique Wasserski sci nautico 319 STEM ciencias puras science pure exakte Wissenschaft scienze pure 320 social science ciencias sociales sciences sociales Sozialwissenschaft scienze sociali 321 sculpture escultura sculpture Skulptur scultura 322 school systems escuela \u00e9cole Schule scuola 323 forestry silvicultura sylviculture Waldbau selvicoltura 324 social services servicios sociales services sociaux Sozialdienst servizi sociali 325 sexology sexolog\u00eda sexologie Sexologie sessuologia 326 sects sectas sectes Sekten sette 327 security and public safety seguridad social s\u00e9curit\u00e9 sociale Sozialdienstleistungen sicurezza sociale 328 iron metallurgy siderurgia sid\u00e9rurgie Eisen- und Stahlindustrie siderurgia 329 unions sindicatos syndicats Gewerkschaften sindacati 330 seismology sismolog\u00eda sismologie Seismologie sismologia 331 operating systems sistemas operativos syst\u00e8me d'exploitation Betriebssysteme sistemi operativi 332 mining industry industria de la extracci\u00f3n industrie extractive Bergbau industria estrattiva 333 mushing carreras de trineo tra\u00eenage Schlittenhund sleddog 334 sledding trineo luge Schlitten slittino 335 snowboard snowboard snowboard Snowboard snowboard 336 sociology sociolog\u00eda sociologie Soziologie sociologia 337 softball s\u00f3fbol softball Softball softball 338 software software logiciel Software software 339 entertainment espect\u00e1culo spectacle Show spettacolo 340 sports deportes sport Sport sport 341 squash squash squash Squash squash 342 printing imprenta impression Druck stampa 343 printers impresoras imprimantes Druckers stampanti 344 statistics estad\u00edstica statistique Statistik statistica 345 history historia histoire Geschichte storia 346 ancient history historia antigua histoire ancienne alte Geschichte storia antica 347 contemporary history historia contempor\u00e1nea histoire contemporaine Zeitgeschichte storia contemporanea 348 medieval history historia medieval histoire du moyen \u00e2ge mittelalterliche Geschichte storia medievale 349 modern history historia moderna histoire des temps modernes moderne Geschichte storia moderna 350 roads and traffic carretera route Autobahn strada 351 musical instruments instrumentos musicales instruments de musique Musikinstrumente strumenti 352 hospitality facilities instalaciones tur\u00edsticas activit\u00e9s touristiques touristische Anlagen strutture turistiche 353 numismatics (study) estudio de las monedas \u00e9tude de monnaie M\u00fcnzkunde studio delle monete 354 scuba diving actividades submarinas plong\u00e9e Tauchen subacquea 355 surfing surf surf Surf surf 356 theatre teatro th\u00e9\u00e2tre Theater teatro 357 technical drawing t\u00e9cnica technicisme mechanische Zeichnung tecnica 358 technology tecnolog\u00eda technologie Technologie tecnologia 359 telecommunications telecomunicaciones t\u00e9l\u00e9communication Telekommunikation telecomunicazioni 360 telephony telefon\u00eda t\u00e9l\u00e9phonie Telefonie telefonia 361 telegraph tel\u00e9grafo t\u00e9l\u00e9graphe Telegraph telegrafo 362 television televisi\u00f3n t\u00e9l\u00e9vision Fernsehen televisione 363 tennis tenis tennis Tennis tennis 364 theology teolog\u00eda th\u00e9ologie Theologie teologia 365 thermohydraulics termohidr\u00e1ulica thermohydraulique Thermohydraulik termo-idraulica 366 thermodynamics termodin\u00e1mica thermodynamique Thermodynamik termodinamica 367 textiles tejidos tissus Stoff tessuti 368 target-shooting tiro al blanco tir \u00e0 la cible Scheibenschie\u00dfen tiro a segno 369 skeet shooting tiro al plato tir au pigeon Tontaubenschie\u00dfen tiro al piattello 370 topography topograf\u00eda topographie Topographie topografia 371 transportation transportes transports Transporte trasporti 372 trekking senderismo trekking Trekking trekking 373 diving saltos plongeon Wasserspringen tuffi 374 tourism turismo tourisme Tourismus turismo 375 crochet ganchillo crochet H\u00e4kelei uncinetto 376 university universidad universit\u00e9 Universit\u00e4t universit\u00e0 377 city planning urbanismo urbanisme Stadtplanung urbanistica 378 sailing vela voile Segeln vela 379 veterinary science veterinaria m\u00e9decine v\u00e9t\u00e9rinaire Tiermedizin veterinaria 380 glassware vidrer\u00eda verrerie Glasgeschirr vetreria 381 video games videojuegos jeux vid\u00e9o Videospiele videogiochi 382 wine industry viticultura viticulture Weinanbau viticoltura 383 volcanology vulcanolog\u00eda volcanologie Vulkanologie vulcanologia 384 windsurfing windsurf planche \u00e0 voile Windsurf windsurf 385 zoology zoolog\u00eda zoologie Zoologie zoologia 386 zootechnics zootecnia zootechnie Tierzucht zootecnia 387 bureaucratic terminology t\u00e9rminos burocr\u00e1ticos termes bureaucratiques b\u00fcrokratische Begriffe termini burocratici 388 scientific terms t\u00e9rminos cient\u00edficos termes scientifiques wissenschaftliche Begriffe termini scientifici 389 technical terminology t\u00e9rminos t\u00e9cnicos termes techniques Fachbegriffe termini tecnici 390 cosmetic industry industria cosm\u00e9tica industrie de la cosm\u00e9tique Kosmetikindustrie industria cosmetica 391 gymnastics gimnasia gymnastique Gymnastik ginnastica 392 rhythmic gymnastics gimnasia r\u00edtmica gymnastique rythmique Calisthenics ginnastica ritmica 393 artistic gymnastics gimnasia art\u00edstica gymnastique sportive Kunstturnen ginnastica artistica 394 lawn bowls juego de las bochas jeu de boules Kugelsport gioco delle bocce 395 checkers damas dames Damespiel dama 396 science fiction ciencia ficci\u00f3n science-fiction Science-Fiction fantascienza 397 accounting contabilidad comptabilit\u00e9 Buchhaltung contabilit\u00e0 398 marine biology biolog\u00eda marina biologie marine Meeresbiologie biologia marina 399 parachuting paracaidismo parachutisme Fallschirmspringen paracadutismo 400 gambling juego de azar jeux de hasard Gl\u00fccksspiel gioco d'azzardo 401 karate k\u00e1rate karat\u00e9 Karate karate 402 typewriting dactilograf\u00eda dactylographie Maschinenschreiben dattilografia 403 shorthand estenograf\u00eda st\u00e9nographie Kurzschrift stenografia 404 Hinduism hinduismo hindouisme Hinduismus induismo 405 polo polo polo Polo polo 406 pornography pornograf\u00eda pornographie Pornographie pornografia","title":"Topics"},{"location":"reference/topics/#standard-topics","text":"Here are the topics that keyphrase extraction can detect. The first column shows the identification number of the topic, which is the same for all languages. The other columns show the topic labels, which vary by language. ID English Spanish French German Italian 0 clothing vestuario v\u00eatements Kleidung abbigliamento 1 homeopathy homeopat\u00eda hom\u00e9opathie Hom\u00f6opathie omeopatia 2 clothing accessories accesorios accessoire Kleidungszubeh\u00f6r accessori 3 acoustics ac\u00fastica acoustique Akustik acustica 4 aviation aeron\u00e1utica a\u00e9ronautique Aeronautik aeronautica 5 air force aeron\u00e1utica militar a\u00e9ronautique militaire Luftwaffe aeronautica militare 6 aeronautic technology aerotecnia a\u00e9rotechnique Luftzeugtechnik aerotecnica 7 agriculture agricultura agriculture Landwirtschaft agricoltura 8 food alimentos nourriture Lebensmittel alimenti 9 animal husbandry crianza y ganader\u00eda \u00e9levage Zucht allevamento 10 mountaineering alpinismo alpinisme Bergsteigen alpinismo 11 anatomy anatom\u00eda anatomie Anatomie anatomia 12 antique trade comercio de antig\u00fcedades antiquit\u00e9 Antiquit\u00e4ten antiquariato 13 anthropology antropolog\u00eda anthropologie Anthropologie antropologia 14 free diving apnea apn\u00e9e Atemstillstand apnea 15 heraldry her\u00e1ldica h\u00e9raldique Heraldik araldica 16 archaeology arqueolog\u00eda arch\u00e9ologie Arch\u00e4ologie archeologia 17 architecture arquitectura architecture Architektur architettura 18 archival studies archiv\u00edstica archivage Archivierung archivistica 19 archery arco arc Bogenschie\u00dfen arco 20 arithmetic aritm\u00e9tica arithm\u00e9tique Arithmetik aritmetica 21 weapons armas armes Bewaffnung armi 22 interior design decoraci\u00f3n ameublement Innenausstattung arredamento 23 art arte art Kunst arte 24 martial arts artes marciales arts martiaux Kampfsport arti marziali 25 crafts artesan\u00eda artisanat Handwerk artigianato 26 artistic crafts artesan\u00eda art\u00edstica artisanat d'art Kunsthandwerk artigianato artistico 27 visual arts artes gr\u00e1ficas graphique graphische Kunst arti grafiche 28 artillery artiller\u00eda artillerie Artillerie artiglieria 29 insurance industry seguros assurance Versicherung assicurazioni 30 auction subastas vente Auktion aste 31 astrophysics astrof\u00edsica astrophysique Astrophysik astrofisica 32 astrology astrolog\u00eda astrologie Astrologie astrologia 33 astronautics astron\u00e1utica astronautique Raumfahrt astronautica 34 astronomy astronom\u00eda astronomie Astronomie astronomia 35 culture t\u00e9rminos culturales termes culturels kulturelle Begriffe termini culturali 36 athletics atletismo athl\u00e9tisme Leichtathletik atletica leggera 37 wrestling and weightlifting halterofilia y lucha halt\u00e9rophilie Schwerathletik atletica pesante 38 automation automatizaci\u00f3n automation Automatisierung automazione 39 motor vehicles veh\u00edculos de motor v\u00e9hicule automobile Kraftfahrzeug autoveicoli 40 motor racing automovilismo automobilisme Motorsport automobilismo 41 air travel aviaci\u00f3n aviation Luftfahrt aviazione 42 ballistics bal\u00edstica balistique Ballistik balistica 43 ballet ballet-baile ballet Ballett balletto-danza 44 banking banco banque Bank banca 45 baseball b\u00e9isbol base-ball Baseball baseball 46 The Bible Biblia Bible Bibel Bibbia 47 libraries bibliotecas biblioth\u00e8que Bibliotheken biblioteche 48 billiard sports billar billard Billard biliardo 49 biochemistry bioqu\u00edmica biochimie Biochemie biochimica 50 biophysics biof\u00edsica biophysique Biophysik biofisica 51 biology biolog\u00eda biologie Biologie biologia 52 biotechnology biotecnolog\u00eda biotechnologie Biotechnologie biotecnologie 53 bobsledding bobsleigh bob Bob bob 54 stock exchange bolsa Bourse B\u00f6rse borsa 55 botany bot\u00e1nica botanique Botanik botanica 56 bowling bolos bowling Bowling bowling 57 boxing boxeo boxe Boxen boxe 58 do it yourself bricolaje bricolage do it yourself bricolage 59 bridge (card game) bridge bridge Bridge bridge 60 Buddhism budismo bouddhisme Buddhismus buddismo 61 hunting caza chasse Jagd caccia 62 CAD (computer aided design) cad cad CAD (rechnerunterst\u00fctzte Konstruktion) cad 63 five-a-side football f\u00fatbol sala football \u00e0 cinq Futsal calcetto 64 soccer (US) f\u00fatbol football Fu\u00dfball calcio 65 footwear calzados chaussure Schuhwerk calzature 66 rowing pirag\u00fcismo aviron Rudern canottaggio 67 singing canto chant Gesang canto 68 coal mining carb\u00f3n charbonnage Kohlebergwerk carbone 69 cardiology cardiolog\u00eda cardiologie Kardiologie cardiologia 70 cartography cartograf\u00eda cartographie Kartographie cartografia 71 pottery cer\u00e1mica c\u00e9ramique T\u00f6pferei ceramica 72 chemistry qu\u00edmica chimie Chemie chimica 73 inorganic chemistry qu\u00edmica inorg\u00e1nica chimie inorganique anorganische Chemie chimica inorganica 74 organic chemistry qu\u00edmica org\u00e1nica chimie organique organische Chemie chimica organica 75 surgery cirug\u00eda chirurgie Chirurgie chirurgia 76 cycling ciclismo cyclisme Radfahren ciclismo 77 film industry cine cin\u00e9ma Kino cinema 78 circus circo cirque Zirkus circo 79 track cycling ciclismo en pista cyclisme sur piste Bahnrennen ciclismo su pista 80 cytology citolog\u00eda cytologie Zytologie citologia 81 collecting coleccionismo collection Sammeln collezionismo 82 trade comercio commerce Handel commercio 83 electronic components piezas electr\u00f3nicas composants \u00e9lectroniques elektronischen Komponenten componenti elettronici 84 music composition composici\u00f3n composition Komposition composizione 85 computer art infoarte computer art Computerkunst computer art 86 computer graphics infograf\u00eda infographie Grafik computer grafica 87 media and communication comunicaci\u00f3n communication Massenkommunikation comunicazione 88 leather processing curtidur\u00eda tannerie Gerberei conceria 89 beauty products cosm\u00e9tica cosm\u00e9tologie Kosmetika cosmesi 90 cosmography cosmograf\u00eda cosmographie Kosmographie cosmografia 91 cricket cr\u00edquet cricket Kricket cricket 92 crime criminalidad criminalit\u00e9 Kriminalit\u00e4t criminalit\u00e0 93 Christianity cristianismo Christianisme Christentum cristianesimo 94 news cr\u00f3nica chronique Nachrichten cronaca 95 database base de datos base de donn\u00e9es Datenbank database 96 decoupage decoupage d\u00e9coupage Serviettentechnik decoupage 97 dermatology dermatolog\u00eda dermatologie Dermatologie dermatologia 98 teaching methodology did\u00e1ctica didactique Didaktik didattica 99 dietetics diet\u00e9tica di\u00e9t\u00e9tique Di\u00e4tetik dietetica 100 diplomacy diplomacia diplomatie Diplomatie diplomazia 101 law derecho droit Gesetz diritto 102 non-criminal law derecho civil droit civil Zivilrecht diritto civile 103 business and commercial law derecho mercantil droit commercial Handelsrecht diritto commerciale 104 international law derecho internacional droit international V\u00f6lkerrecht diritto internazionale 105 criminal law derecho penal droit p\u00e9nal Strafrecht diritto penale 106 private law derecho privado droit priv\u00e9 Privatrecht diritto privato 107 administrative law derecho p\u00fablico y administrativo droit public et administratif Staats-und Verwaltungsrecht diritto pubblico e amministrativo 108 electronic storage discos disques Festplatten dischi 109 illustration dibujo dessin Zeichnung disegno 110 Judaism hebra\u00edsmo juda\u00efsme Judentum ebraismo 111 ecology ecolog\u00eda \u00e9cologie \u00d6kologie ecologia 112 e-commerce comercio electr\u00f3nico e-commerce E-Commerce e-commerce 113 the economy econom\u00eda \u00e9conomie Wirtschaft economia 114 construction industry construcci\u00f3n construction Bauindustrie edilizia 115 publishing industria editorial \u00e9dition Verlagswesen editoria 116 electricity electricidad \u00e9lectricit\u00e9 Elektrizit\u00e4t elettricit\u00e0 117 electronics electr\u00f3nica \u00e9lectronique Elektronik elettronica 118 electrotechnics electrot\u00e9cnica \u00e9lectrotechnique Elektrotechnik elettrotecnica 119 e-mail e-mail e-mail E-Mail e-mail 120 embryology embriolog\u00eda embryologie Embryologie embriologia 121 energy energ\u00eda \u00e9nergie Energie energia 122 puzzles enigm\u00edstica jeux d'esprit R\u00e4tsel enigmistica 123 enology enolog\u00eda \u0153nologie \u00d6nologie enologia 124 entomology entomolog\u00eda entomologie Insektenkunde entomologia 125 epigraphy epigraf\u00eda \u00e9pigraphie Epigraphie epigrafia 126 equitation equitaci\u00f3n \u00e9quitation Reitsport equitazione 127 ethics \u00e9tica \u00e9thique Ethik etica 128 Islam islam islam Islam islam 129 ethnology etnolog\u00eda ethnologie Ethnologie etnologia 130 TV broadcasting eventos televisivos \u00e9v\u00e9nements t\u00e9l\u00e9vis\u00e9s Rundfunk Veranstaltungen eventi televisivi 131 evolution evoluci\u00f3n \u00e9volution Evolution evoluzione 132 carpentry carpinter\u00eda menuiserie Zimmerei falegnameria 133 pharmaceuticals farmacia pharmacie Pharmazie farmacia 134 pharmacology farmacolog\u00eda pharmacologie Pharmakologie farmacologia 135 trains ferrocarril chemin de fer Eisenbahn ferrovia 136 philately filatelia philat\u00e9lie Briefmarkensammeln filatelia 137 philology filolog\u00eda philologie Philologie filologia 138 philosophy filosof\u00eda philosophie Philosophie filosofia 139 finance finanzas finance Finanz finanza 140 finance (private) finanzas privadas finances priv\u00e9es Privatfinanz finanza privata 141 public financing finanzas p\u00fablicas finances publiques \u00f6ffentliche Finanz finanza pubblica 142 revenue services fisco fisc Einnahmen fisco 143 physics f\u00edsica physique Physik fisica 144 atomic physics f\u00edsica at\u00f3mica physique atomique Atomphysik fisica atomica 145 physiology fisiolog\u00eda physiologie Physiologie fisiologia 146 phytopathology fitopatolog\u00eda phytopathologie Phytopathologie fitopatologia 147 folklore folclore folklore Volkskunde folclore 148 phonetics fon\u00e9tica phon\u00e9tique Phonetik fonetica 149 phonology fonolog\u00eda phonologie Phonologie fonologia 150 American football f\u00fatbol americano football am\u00e9ricain American Football football americano 151 photography fotograf\u00eda photographie Fotografie fotografia 152 artistic photography fotograf\u00eda art\u00edstica photographie artistique k\u00fcnstlerische Fotografie fotografia artistica 153 free climbing escalada libre free climbing Klettern free climbing 154 fruit growing fruticultura arboriculture fruiti\u00e8re Obstbau frutticoltura 155 cartoons and comic books historieta bande dessin\u00e9e Comics fumetto 156 art galleries galer\u00edas galerie Galerie gallerie 157 gastronomy gastronom\u00eda gastronomie Gastronomie gastronomia 158 genealogy genealog\u00eda g\u00e9n\u00e9alogie Genealogie genealogia 159 genetics gen\u00e9tica g\u00e9n\u00e9tique Genetik genetica 160 geophysics geof\u00edsica g\u00e9ophysique Geophysik geofisica 161 geography geograf\u00eda g\u00e9ographie Geographie geografia 162 geology geolog\u00eda g\u00e9ologie Geologie geologia 163 geometry geometr\u00eda g\u00e9om\u00e9trie Geometrie geometria 164 gardening jardiner\u00eda jardinage G\u00e4rtnerei giardinaggio 165 toys juguetes jouets Spielzeuge giocattoli 166 card games juegos de naipes jeux de cartes Kartenspielen giochi con le carte 167 games and toys juego jeu Spiel gioco 168 jewelry joyer\u00eda bijouterie Schmuck gioielleria 169 the press peri\u00f3dicos journaux Zeitungen giornali 170 journalism periodismo journalisme Journalismus giornalismo 171 go-karting kart go-kart Go-Kart go kart 172 golf golf golf Golf golf 173 graffiti grafiti graffiti Graffito graffiti 174 grammar and syntax gram\u00e1tica grammaire Grammatik grammatica 175 computer hardware hardware mat\u00e9riel Hardware hardware 176 hockey hockey hockey Hockey hockey 177 ice hockey hockey sobre hielo hockey sur glace Eishockey hockey su ghiaccio 178 hydraulics hidr\u00e1ulica hydraulique Hydraulik idraulica 179 immunology inmunolog\u00eda immunologie Immunologie immunologia 180 business empresa entreprise Firma impresa 181 engraving grabado gravure Gravierung incisione 182 industry industria industrie Industrie industria 183 aeronautics industry industria aeron\u00e1utica industrie a\u00e9ronautique Luftfahrtindustrie industria aeronautica 184 food industry industria alimentaria industrie alimentaire Lebensmittelindustrie industria alimentare 185 automotive industry industria automov\u00edlistica industrie automobile Autoindustrie industria automobilistica 186 arms industry industria b\u00e9lica industrie de guerre Kriegsindustrie industria bellica 187 footwear industry industria del calzado industrie de la chaussure Schuhindustrie industria calzaturiera 188 ceramic industry industria cer\u00e1mica industrie c\u00e9ramique Keramikindustrie industria ceramica 189 chemical industry industria qu\u00edmica industrie chimique Chemieindustrie industria chimica 190 rail transport industria del ferrocarril industrie de chemin de fer Eisenbahnindustrie industria ferroviaria 191 furniture industry industria mueblera industrie des meubles M\u00f6belindustrie industria mobiliera 192 motorcycle industry industria motociclista industrie de motos Motorrad-Industrie industria motociclistica 193 shipbuilding industria n\u00e1utica industrie naval Schifffahrtsindustrie industria nautica 194 textile industry industria textil industrie textiles Textilindustrie industria tessile 195 glass manufacturing industria del vidrio industrie de verre Glasherstellung industria vetraria 196 industrial design dise\u00f1o industrial dessin industriel Industriedesign industrial design 197 computer science inform\u00e1tica informatique Informatik informatica 198 engineering ingenier\u00eda g\u00e9nie Ingenieurwesen ingegneria 199 aerospace engineering ingenier\u00eda aeroespacial g\u00e9nie a\u00e9rospatial Luft- und Raumfahrttechnik ingegneria aerospaziale 200 Internet internet internet Internet internet 201 intranet intranet intranet Intranet intranet 202 equestrian sports h\u00edpica hippisme Pferderennen ippica 203 institutions instituciones institutions Institute istituzioni 204 education instrucci\u00f3n enseignement Bildung istruzione 205 ichthyology ictiolog\u00eda ichtyologie Fischkunde ittiologia 206 kayaking kayak kayak Kajak kayak 207 needlework trabajos de cosido ouvrage d'aiguilles Nadelarbeit lavori di cucito 208 job market trabajo travail Arbeit lavoro 209 legislation legislaci\u00f3n l\u00e9gislation Gesetzgebung legislazione 210 judo judo judo Judo judo 211 literature literatura litt\u00e9rature Literatur letteratura 212 linguistics ling\u00fc\u00edstica linguistique Linguistik linguistica 213 lithography litograf\u00eda lithographie Lithographie litografia 214 liturgy liturgia liturgie Liturgie liturgia 215 lottery loter\u00eda loterie Lotterie lotterie 216 animal slaughter mataderos abattage Schlachtung macellazione 217 knitting punto tricot Stricken maglia 218 manufacturing manufactura manufacture Herstellung manifattura 219 watercraft and nautical navigation marina marine Flotte marina 220 naval forces marina militar marine militaire Marine marina militare 221 marketing marketing marketing Marketing marketing 222 mathematics matem\u00e1tica math\u00e9matiques Mathematik matematica 223 mechanics mec\u00e1nica m\u00e9canique Mechanik meccanica 224 public administration administraci\u00f3n p\u00fablica administration publique Beh\u00f6rde amministrazione pubblica 225 medicine medicina m\u00e9decine Medizin medicina 226 alternative medicine medicina alternativa m\u00e9decine douce Alternative Medizin medicina alternativa 227 data storage memoria m\u00e9moire Speicher memoria 228 board games juegos de mesa jeux de table Brettspiele giochi da tavolo 229 metallurgy metalurgia m\u00e9tallurgie Metallurgie metallurgia 230 meteorology meteorolog\u00eda m\u00e9t\u00e9orologie Meteorologie meteorologia 231 meter and prosody m\u00e9trica m\u00e9trique Metrik metrica 232 ophthalmology oftalmolog\u00eda ophtalmologie Augenheilkunde oculistica 233 microbiology microbiolog\u00eda microbiologie Mikrobiologie microbiologia 234 armed forces militar militaire Milit\u00e4r militare 235 mineralogy mineralog\u00eda min\u00e9ralogie Mineralogie mineralogia 236 mines minas mines Minen miniere 237 government departments and ministries ministerios Minist\u00e8res Ministerien ministeri 238 rocket science tecnolog\u00eda misil\u00edstica missile Raketen missilistica 239 mythology mitolog\u00eda mythologie Mythologie mitologia 240 furniture muebles meubles M\u00f6blierung mobili 241 fashion moda mode Mode moda 242 computer monitor monitor \u00e9cran Monitor monitor 243 motorcycling motociclismo motocyclisme Motorradfahren motociclismo 244 powertrain design and engineering ingenier\u00eda mec\u00e1nica sports motoris\u00e9s Design und Technik motoristica 245 multimedia multimedia multim\u00e9dia Multimedia multimedia 246 masonry alba\u00f1iler\u00eda ma\u00e7onnerie Mauerwerk muratura 247 museums museos mus\u00e9es Museen musei 248 music m\u00fasica musique Musik musica 249 numismatics numism\u00e1tica numismatique Numismatik numismatica 250 swimming nataci\u00f3n nage Schwimmen nuoto 251 occultism ocultismo occultisme Okkultismus occultismo 252 hydrography hidrograf\u00eda hydrographie Hydrographie idrografia 253 orthodontics odontolog\u00eda odontologie Kieferorthop\u00e4die odontoiatria 254 oncology oncolog\u00eda oncologie Onkologie oncologia 255 opera \u00f3pera op\u00e9ra Oper opera 256 goldsmithing orfebrer\u00eda orf\u00e8vrerie Juwelierskunst oreficeria 257 ornithology ornitolog\u00eda ornithologie Vogelkunde ornitologia 258 watchmaking relojer\u00eda horlogerie Uhrenindustrie orologeria 259 orthopedics ortopedia orthop\u00e9die Orthop\u00e4die ortopedia 260 hospitals hospital h\u00f4pital Krankenhaus ospedale 261 optics \u00f3ptica optique Optik ottica 262 paleography paleograf\u00eda pal\u00e9ographie Pal\u00e4ographie paleografia 263 paleontology paleontolog\u00eda pal\u00e9ontologie Pal\u00e4ontologie paleontologia 264 paleozoology paleozoolog\u00eda pal\u00e9ozoologie Pal\u00e4ozoologie paleozoologia 265 basketball baloncesto basket-ball Basketball pallacanestro 266 handball balonmano handball Handball pallamano 267 water polo polo acu\u00e1tico water-polo Wasserball pallanuoto 268 volleyball voleibol volley-ball Volleyball pallavolo 269 papyrology papirolog\u00eda papyrologie Papyrologie papirologia 270 parapsychology parapsicolog\u00eda parapsychologie Parapsychologie parapsicologia 271 Parliament and legislative bodies parlamento parlement Parlament parlamento 272 skating patinaje patinage Schlittschuhlaufen pattinaggio 273 pedagogy pedagog\u00eda p\u00e9dagogie P\u00e4dagogie pedagogia 274 classical music m\u00fasica cl\u00e1sica musique classique klassische Musik musica classica 275 fishing pesca p\u00eache Angeln pesca 276 sport fishing pesca deportiva p\u00eache sportive Sportfischen pesca sportiva 277 spearfishing pesca submarina p\u00eache sous-marine Unterwasserfischen pesca subacquea 278 petrochemistry petroqu\u00edmica p\u00e9trochimie Petrochemie petrolchimica 279 petrochemicals petr\u00f3leo p\u00e9trole \u00d6l petrolio 280 table tennis ping-pong ping-pong Tischtennis ping-pong 281 painting pintura peinture Malerei pittura 282 glass painting pintura sobre vidrio peinture sur verre Glasmalerei pittura vetraria 283 poetry poes\u00eda po\u00e9sie Poesie poesia 284 poker p\u00f3quer poker Poker poker 285 politics pol\u00edtica politique Politik politica 286 police polic\u00eda police Polizei polizia 287 postal service correo poste Post posta 288 prehistory prehistoria pr\u00e9histoire Vorgeschichte preistoria 289 welfare previsi\u00f3n \u00e9tat providence Wohlfahrt previdenza 290 computer processors procesadores processeurs Prozessoren processori 291 perfumery perfumer\u00eda parfumerie Parf\u00fcmerie profumeria 292 computer programming programaci\u00f3n programmation Programmierung programmazione 293 office productivity software programas para la oficina programme de bureau Business-Programme programmi per ufficio 294 psychoanalysis psicoan\u00e1lisis psychanalyse Psychoanalyse psicanalisi 295 psychiatry psiquiatr\u00eda psychiatrie Psychiatrie psichiatria 296 psychology psicolog\u00eda psychologie Psychologie psicologia 297 advertising publicidad publicit\u00e9 Werbung pubblicit\u00e0 298 radio broadcasting radio radio Radio radio 299 radiology radiolog\u00eda radiologie Radiologie radiologia 300 kitchen tools utensilios de cocina ustensiles de cuisine K\u00fcchenutensilien strumenti da cucina 301 public relations relaciones p\u00fablicas relations publiques Public Relations relazioni pubbliche 302 religion religi\u00f3n religion Verehrung religione 303 information technology redes r\u00e9seaux Netze reti 304 rhetoric ret\u00f3rica rh\u00e9torique Rhetorik retorica 305 lacework bordado broderie Spitze ricamo 306 restaurant industry restauraci\u00f3n restauration Catering ristorazione 307 robotics rob\u00f3tica robotique Robotik robotica 308 rugby rugby rugby Rugby rugby 309 health care sanidad sant\u00e9 Gesundheitsamt sanit\u00e0 310 tailoring sastrer\u00eda haute couture Schneiderei sartoria 311 chess ajedrez \u00e9checs Schach scacchi 312 scenography escenograf\u00eda sc\u00e9nographie Szenografie scenografia 313 graphics card tarjetas gr\u00e1ficas cartes graphiques Grafikkarten schede grafiche 314 fencing esgrima escrime Fechten scherma 315 skiing esqu\u00ed ski Skifahren sci 316 downhill skiing esqu\u00ed alpino ski alpin Abfahrtsski sci alpino 317 cross-country skiing esqu\u00ed de fondo ski de fond Langlauf sci di fondo 318 water skiing esqu\u00ed n\u00e1utico ski nautique Wasserski sci nautico 319 STEM ciencias puras science pure exakte Wissenschaft scienze pure 320 social science ciencias sociales sciences sociales Sozialwissenschaft scienze sociali 321 sculpture escultura sculpture Skulptur scultura 322 school systems escuela \u00e9cole Schule scuola 323 forestry silvicultura sylviculture Waldbau selvicoltura 324 social services servicios sociales services sociaux Sozialdienst servizi sociali 325 sexology sexolog\u00eda sexologie Sexologie sessuologia 326 sects sectas sectes Sekten sette 327 security and public safety seguridad social s\u00e9curit\u00e9 sociale Sozialdienstleistungen sicurezza sociale 328 iron metallurgy siderurgia sid\u00e9rurgie Eisen- und Stahlindustrie siderurgia 329 unions sindicatos syndicats Gewerkschaften sindacati 330 seismology sismolog\u00eda sismologie Seismologie sismologia 331 operating systems sistemas operativos syst\u00e8me d'exploitation Betriebssysteme sistemi operativi 332 mining industry industria de la extracci\u00f3n industrie extractive Bergbau industria estrattiva 333 mushing carreras de trineo tra\u00eenage Schlittenhund sleddog 334 sledding trineo luge Schlitten slittino 335 snowboard snowboard snowboard Snowboard snowboard 336 sociology sociolog\u00eda sociologie Soziologie sociologia 337 softball s\u00f3fbol softball Softball softball 338 software software logiciel Software software 339 entertainment espect\u00e1culo spectacle Show spettacolo 340 sports deportes sport Sport sport 341 squash squash squash Squash squash 342 printing imprenta impression Druck stampa 343 printers impresoras imprimantes Druckers stampanti 344 statistics estad\u00edstica statistique Statistik statistica 345 history historia histoire Geschichte storia 346 ancient history historia antigua histoire ancienne alte Geschichte storia antica 347 contemporary history historia contempor\u00e1nea histoire contemporaine Zeitgeschichte storia contemporanea 348 medieval history historia medieval histoire du moyen \u00e2ge mittelalterliche Geschichte storia medievale 349 modern history historia moderna histoire des temps modernes moderne Geschichte storia moderna 350 roads and traffic carretera route Autobahn strada 351 musical instruments instrumentos musicales instruments de musique Musikinstrumente strumenti 352 hospitality facilities instalaciones tur\u00edsticas activit\u00e9s touristiques touristische Anlagen strutture turistiche 353 numismatics (study) estudio de las monedas \u00e9tude de monnaie M\u00fcnzkunde studio delle monete 354 scuba diving actividades submarinas plong\u00e9e Tauchen subacquea 355 surfing surf surf Surf surf 356 theatre teatro th\u00e9\u00e2tre Theater teatro 357 technical drawing t\u00e9cnica technicisme mechanische Zeichnung tecnica 358 technology tecnolog\u00eda technologie Technologie tecnologia 359 telecommunications telecomunicaciones t\u00e9l\u00e9communication Telekommunikation telecomunicazioni 360 telephony telefon\u00eda t\u00e9l\u00e9phonie Telefonie telefonia 361 telegraph tel\u00e9grafo t\u00e9l\u00e9graphe Telegraph telegrafo 362 television televisi\u00f3n t\u00e9l\u00e9vision Fernsehen televisione 363 tennis tenis tennis Tennis tennis 364 theology teolog\u00eda th\u00e9ologie Theologie teologia 365 thermohydraulics termohidr\u00e1ulica thermohydraulique Thermohydraulik termo-idraulica 366 thermodynamics termodin\u00e1mica thermodynamique Thermodynamik termodinamica 367 textiles tejidos tissus Stoff tessuti 368 target-shooting tiro al blanco tir \u00e0 la cible Scheibenschie\u00dfen tiro a segno 369 skeet shooting tiro al plato tir au pigeon Tontaubenschie\u00dfen tiro al piattello 370 topography topograf\u00eda topographie Topographie topografia 371 transportation transportes transports Transporte trasporti 372 trekking senderismo trekking Trekking trekking 373 diving saltos plongeon Wasserspringen tuffi 374 tourism turismo tourisme Tourismus turismo 375 crochet ganchillo crochet H\u00e4kelei uncinetto 376 university universidad universit\u00e9 Universit\u00e4t universit\u00e0 377 city planning urbanismo urbanisme Stadtplanung urbanistica 378 sailing vela voile Segeln vela 379 veterinary science veterinaria m\u00e9decine v\u00e9t\u00e9rinaire Tiermedizin veterinaria 380 glassware vidrer\u00eda verrerie Glasgeschirr vetreria 381 video games videojuegos jeux vid\u00e9o Videospiele videogiochi 382 wine industry viticultura viticulture Weinanbau viticoltura 383 volcanology vulcanolog\u00eda volcanologie Vulkanologie vulcanologia 384 windsurfing windsurf planche \u00e0 voile Windsurf windsurf 385 zoology zoolog\u00eda zoologie Zoologie zoologia 386 zootechnics zootecnia zootechnie Tierzucht zootecnia 387 bureaucratic terminology t\u00e9rminos burocr\u00e1ticos termes bureaucratiques b\u00fcrokratische Begriffe termini burocratici 388 scientific terms t\u00e9rminos cient\u00edficos termes scientifiques wissenschaftliche Begriffe termini scientifici 389 technical terminology t\u00e9rminos t\u00e9cnicos termes techniques Fachbegriffe termini tecnici 390 cosmetic industry industria cosm\u00e9tica industrie de la cosm\u00e9tique Kosmetikindustrie industria cosmetica 391 gymnastics gimnasia gymnastique Gymnastik ginnastica 392 rhythmic gymnastics gimnasia r\u00edtmica gymnastique rythmique Calisthenics ginnastica ritmica 393 artistic gymnastics gimnasia art\u00edstica gymnastique sportive Kunstturnen ginnastica artistica 394 lawn bowls juego de las bochas jeu de boules Kugelsport gioco delle bocce 395 checkers damas dames Damespiel dama 396 science fiction ciencia ficci\u00f3n science-fiction Science-Fiction fantascienza 397 accounting contabilidad comptabilit\u00e9 Buchhaltung contabilit\u00e0 398 marine biology biolog\u00eda marina biologie marine Meeresbiologie biologia marina 399 parachuting paracaidismo parachutisme Fallschirmspringen paracadutismo 400 gambling juego de azar jeux de hasard Gl\u00fccksspiel gioco d'azzardo 401 karate k\u00e1rate karat\u00e9 Karate karate 402 typewriting dactilograf\u00eda dactylographie Maschinenschreiben dattilografia 403 shorthand estenograf\u00eda st\u00e9nographie Kurzschrift stenografia 404 Hinduism hinduismo hindouisme Hinduismus induismo 405 polo polo polo Polo polo 406 pornography pornograf\u00eda pornographie Pornographie pornografia","title":"Standard topics"},{"location":"requirements/","text":"Requirements Operating system Essex can be run in both Windows and Linux. Windows requirements: Windows 10 or newer Microsoft Visual C++ Redistributable 2017 Linux requirements: Ubuntu 20.04, CentOS 7, Red Hat Enterprise Linux 7 or newer Computing resources The requirements of essex in terms of memory, CPU and disk space are extremely variable from case to case. The factors to be taken into account are: Target performance Complexity of the text intelligence engines, whether they are engines with only the fundamental NLU capabilities or they also carry out classification and information extraction and, in this case, with how many rules and which\u2014if any\u2014scripting functionality Space occupied by the text intelligence engines files Log size and possible use of external log rotation mechanisms For an accurate estimate of the resources needed in your case, please contact your expert.ai representative.","title":"Requirements"},{"location":"requirements/#requirements","text":"","title":"Requirements"},{"location":"requirements/#operating-system","text":"Essex can be run in both Windows and Linux. Windows requirements: Windows 10 or newer Microsoft Visual C++ Redistributable 2017 Linux requirements: Ubuntu 20.04, CentOS 7, Red Hat Enterprise Linux 7 or newer","title":"Operating system"},{"location":"requirements/#computing-resources","text":"The requirements of essex in terms of memory, CPU and disk space are extremely variable from case to case. The factors to be taken into account are: Target performance Complexity of the text intelligence engines, whether they are engines with only the fundamental NLU capabilities or they also carry out classification and information extraction and, in this case, with how many rules and which\u2014if any\u2014scripting functionality Space occupied by the text intelligence engines files Log size and possible use of external log rotation mechanisms For an accurate estimate of the resources needed in your case, please contact your expert.ai representative.","title":"Computing resources"},{"location":"setup-run/","text":"Setup and run Setup Database folder As mentioned in the introduction , essex exposes the functionalities of text intelligence engines prepared with expert.ai Studio. When you deploy a project in Studio, you create a CPK language package. It is a compressed file with the .cpk extension containing all the files that make up the text intelligence engine. Essex requires that the CPK packages corresponding to the text intelligence engines it must manage are located in a database folder, as exemplified in the following image. it is therefore necessary, before being able to run essex, to prepare the database folder in a suitable storage accessible to essex and with enough free space to host all the packages. Info In essex jargon, installed CPK packages are referred to as resources . However, considering that essex has a RESTful API, the term should not be confused with the vaguely similar concept of REST resources . To install to and remove CPK packages from the database, follow the instructions below. Package installation To install the CPK package of a text intelligence engine, run this command: executable -dbpath databasefolderpath -install-cpk cpkfilepath where: executable is the path of the essex executable file. databasefolderpath is the path of the database folder. cpkfilepath is the path of the .cpk file In response to this command, essex creates in the database folder indicated by databasefolderpath a subfolder corresponding to the expansion of the .cpk file. The subfolder name, also called the resource name , is the name of the .cpk file without the extension. The command can be executed regardless of whether essex is already running in single resource or server mode (see below). Package removal To remove a previously installed CPK package you need to ensure that essex if not running in single resource or server mode (see below), then run this command: executable -dbpath databasefolderpath -remove-cpk resourcename where: executable is the path of the essex executable file. databasefolderpath is the path of the database folder. resourcename is the name of the resource, i.e. the subfolder of databasefolderpath in which the CPK package was previously installed. In response to this command, essex removes the resourcename package folder from the the database folder indicated by databasefolderpath . Run essex Essex can run in different modes. Depending on the mode, the format of the request may change. Execution mode is determined by the mode option which default value is s . Single resource mode In single resource mode, essex loads only one text intelligence engine package (CPK) in memory, creating a single running instance of it. One instance can process only one request at a time, so, when it's busy, all other requests are queued and served on a first-in, first-out basis. The syntax is: executable -mode -r -dbpath databasefolderpath -resource resourcename [ -hport httpport ] [ -pem pemfile ] [ -ctimeout calltimeout ] where: executable is the path of the essex executable file, which is essex on Linux and essex.exe on Windows. databasefolderpath is the path of the database folder. resourcename is the name of the folder, located inside the databasefolderpath , containing the resource, i.e. the files of the text intelligence engine package to load. httpport is the TCP port number on which essex listens for HTTP/HTTPS requests for RESTful API resources. The default value is 6090 . pemfile is the path of a .pem file containing SSL private key and certificate. The default value is the empty string, so if the -pem option is not specified, essex API uses the HTTP protocol instead of HTTPS. calltimeout is the timeout, in minutes, before a single call expires. The default value is 10 . A value of 0 means there's no timeout. Server mode In server mode, essex can create multiple in-memory instances of one or more text intelligence engines packages. At startup you don't specify which packages to load, so essex is essentially \"empty\" and idle. When a client application specifies the text intelligence engine it requires, essex loads the corresponding package's files and creates an instance of the engine to serve the request. If an instance of an engine is busy and an analysis request arrives for the same engine, essex tries to fork a new engine instance to handle that request. The syntax is: executable -mode -s -dbpath databasefolderpath [ -hport httpport ] [ -pem pemfile ] [ -core cores ] [ -instance instances ] [ -itimeout instancetimeout ] [ -ctimeout calltimeout ] where: executable is the path of the essex executable file, which is essex on Linux and essex.exe on Windows. databasefolderpath is the path of the database folder. httpport is the TCP port number on which essex listens for HTTP/HTTPS requests for RESTful API resources. The default value is 6090 . pemfile is the path of a .pem file containing SSL private key and certificate. The default value is the empty string, so if the -pem option is not specified, essex API uses the HTTP protocol instead of HTTPS. core is the maximum number of text intellgence engines instances that can run in parallel. The default value is number of cores in the machine. Once this number is reached, analysis requests for any engine are queued. When an instance becomes free, if it is what is needed to serve the first queued request, it is used, otherwise essex tries to load and instantiate the necessary resource. This parameter is used to limit the number of CPU cores used by essex. instance is the maximum number of instances loaded in memory. The default value is double the number of cores in the machine. A new instance is created in memory, until the value of this parameter is reached, when: essex receives a request for analysis with engine \"A\" for which no instances exist in memory (it must be loaded from disk). essex receives a request for analysis with engine \"B\", with one or more instances already in memory, all of which already busy. This parameter is used to limit the maximum memory used by essex. itimeout is the maximum time, in hours, that an instance of an engine remains loaded in memory if it is not used. The default value is 1 . This parameter is used to recycle memory by freeing up space for other instances. A value of 0 means that instances are never unloaded, even if they are not used. Warning Because of their complexity, some text intelligence engines take a significant amount of time to load, so avoid setting too low values for this parameter. calltimeout is the timeout, in minutes, before a single call expires. The default value is 10 . Value 0 means no timeout.","title":"Setup and run"},{"location":"setup-run/#setup-and-run","text":"","title":"Setup and run"},{"location":"setup-run/#setup","text":"","title":"Setup"},{"location":"setup-run/#database-folder","text":"As mentioned in the introduction , essex exposes the functionalities of text intelligence engines prepared with expert.ai Studio. When you deploy a project in Studio, you create a CPK language package. It is a compressed file with the .cpk extension containing all the files that make up the text intelligence engine. Essex requires that the CPK packages corresponding to the text intelligence engines it must manage are located in a database folder, as exemplified in the following image. it is therefore necessary, before being able to run essex, to prepare the database folder in a suitable storage accessible to essex and with enough free space to host all the packages. Info In essex jargon, installed CPK packages are referred to as resources . However, considering that essex has a RESTful API, the term should not be confused with the vaguely similar concept of REST resources . To install to and remove CPK packages from the database, follow the instructions below.","title":"Database folder"},{"location":"setup-run/#package-installation","text":"To install the CPK package of a text intelligence engine, run this command: executable -dbpath databasefolderpath -install-cpk cpkfilepath where: executable is the path of the essex executable file. databasefolderpath is the path of the database folder. cpkfilepath is the path of the .cpk file In response to this command, essex creates in the database folder indicated by databasefolderpath a subfolder corresponding to the expansion of the .cpk file. The subfolder name, also called the resource name , is the name of the .cpk file without the extension. The command can be executed regardless of whether essex is already running in single resource or server mode (see below).","title":"Package installation"},{"location":"setup-run/#package-removal","text":"To remove a previously installed CPK package you need to ensure that essex if not running in single resource or server mode (see below), then run this command: executable -dbpath databasefolderpath -remove-cpk resourcename where: executable is the path of the essex executable file. databasefolderpath is the path of the database folder. resourcename is the name of the resource, i.e. the subfolder of databasefolderpath in which the CPK package was previously installed. In response to this command, essex removes the resourcename package folder from the the database folder indicated by databasefolderpath .","title":"Package removal"},{"location":"setup-run/#run-essex","text":"Essex can run in different modes. Depending on the mode, the format of the request may change. Execution mode is determined by the mode option which default value is s .","title":"Run essex"},{"location":"setup-run/#single-resource-mode","text":"In single resource mode, essex loads only one text intelligence engine package (CPK) in memory, creating a single running instance of it. One instance can process only one request at a time, so, when it's busy, all other requests are queued and served on a first-in, first-out basis. The syntax is: executable -mode -r -dbpath databasefolderpath -resource resourcename [ -hport httpport ] [ -pem pemfile ] [ -ctimeout calltimeout ] where: executable is the path of the essex executable file, which is essex on Linux and essex.exe on Windows. databasefolderpath is the path of the database folder. resourcename is the name of the folder, located inside the databasefolderpath , containing the resource, i.e. the files of the text intelligence engine package to load. httpport is the TCP port number on which essex listens for HTTP/HTTPS requests for RESTful API resources. The default value is 6090 . pemfile is the path of a .pem file containing SSL private key and certificate. The default value is the empty string, so if the -pem option is not specified, essex API uses the HTTP protocol instead of HTTPS. calltimeout is the timeout, in minutes, before a single call expires. The default value is 10 . A value of 0 means there's no timeout.","title":"Single resource mode"},{"location":"setup-run/#server-mode","text":"In server mode, essex can create multiple in-memory instances of one or more text intelligence engines packages. At startup you don't specify which packages to load, so essex is essentially \"empty\" and idle. When a client application specifies the text intelligence engine it requires, essex loads the corresponding package's files and creates an instance of the engine to serve the request. If an instance of an engine is busy and an analysis request arrives for the same engine, essex tries to fork a new engine instance to handle that request. The syntax is: executable -mode -s -dbpath databasefolderpath [ -hport httpport ] [ -pem pemfile ] [ -core cores ] [ -instance instances ] [ -itimeout instancetimeout ] [ -ctimeout calltimeout ] where: executable is the path of the essex executable file, which is essex on Linux and essex.exe on Windows. databasefolderpath is the path of the database folder. httpport is the TCP port number on which essex listens for HTTP/HTTPS requests for RESTful API resources. The default value is 6090 . pemfile is the path of a .pem file containing SSL private key and certificate. The default value is the empty string, so if the -pem option is not specified, essex API uses the HTTP protocol instead of HTTPS. core is the maximum number of text intellgence engines instances that can run in parallel. The default value is number of cores in the machine. Once this number is reached, analysis requests for any engine are queued. When an instance becomes free, if it is what is needed to serve the first queued request, it is used, otherwise essex tries to load and instantiate the necessary resource. This parameter is used to limit the number of CPU cores used by essex. instance is the maximum number of instances loaded in memory. The default value is double the number of cores in the machine. A new instance is created in memory, until the value of this parameter is reached, when: essex receives a request for analysis with engine \"A\" for which no instances exist in memory (it must be loaded from disk). essex receives a request for analysis with engine \"B\", with one or more instances already in memory, all of which already busy. This parameter is used to limit the maximum memory used by essex. itimeout is the maximum time, in hours, that an instance of an engine remains loaded in memory if it is not used. The default value is 1 . This parameter is used to recycle memory by freeing up space for other instances. A value of 0 means that instances are never unloaded, even if they are not used. Warning Because of their complexity, some text intelligence engines take a significant amount of time to load, so avoid setting too low values for this parameter. calltimeout is the timeout, in minutes, before a single call expires. The default value is 10 . Value 0 means no timeout.","title":"Server mode"}]}